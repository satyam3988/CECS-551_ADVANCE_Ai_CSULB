{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "HTyx7PmM8J78"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from keras import models\n",
        "from statistics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense , Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import  backend as K\n",
        "from keras.datasets import mnist\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adagrad\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "2Y3ukyoI8qFb"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "id": "T4E4xC4j8rem"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape, x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KwSlWtX80ZT",
        "outputId": "7d06db3f-025c-4a18-cec1-82daf82b2653"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 32, 32, 3), (10000, 32, 32, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_train /= 255\n",
        "x_test = x_test.astype('float32')\n",
        "x_test /= 255"
      ],
      "metadata": {
        "id": "3Yp3kyXU87eD"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mphFiovq8_7_"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z1cz4tag9JuZ"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = to_categorical(y_train, num_classes = 10)\n",
        "y_test = to_categorical(y_test, num_classes = 10)"
      ],
      "metadata": {
        "id": "Z39coAcu9Nvn"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPRiTBMS9VSh",
        "outputId": "bca5f04d-600a-4ef8-a498-a23891c4c55a"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 10), (10000, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x,val_x,train_y,val_y = train_test_split(x_train, y_train, test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "9pZNI1gp9YPf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjOizN9r-s6C"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NN:\n",
        "      def ADAM(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def RMS(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def SGD(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'SGD', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 64, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def SGD_2(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'tanh', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (2, 2), activation = 'tanh', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'elu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'SGD', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 64, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def ADAM_2(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def RMS_2(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (2, 2), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 64, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def ADAGRAD(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (2, 2), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'Adagrad', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 64, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def ADAGRAD_2(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (4, 4), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (2, 2), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'Adagrad', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 64, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def SGD_3(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(256, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'tanh', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (2, 2), activation = 'tanh', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'elu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(32, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(16, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'SGD', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 64, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def ADAM_3(self):\n",
        "        model = models.Sequential()\n",
        "        model.add(layers.Conv2D(256, (5, 5), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (5, 5), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (3, 3), activation = 'tanh', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(128, (2, 2), activation = 'tanh', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Conv2D(64, (3, 3), activation = 'elu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.25))\n",
        "        model.add(layers.Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.MaxPooling2D(2, 2))\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(layers.Dense(256, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(128, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(64, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(32, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(16, activation = 'relu'))\n",
        "        model.add(layers.BatchNormalization())\n",
        "        model.add(layers.Dropout(0.5))\n",
        "        model.add(layers.Dense(10, activation = 'sigmoid'))\n",
        "        model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "        history = model.fit(x_train, y_train, epochs = 10, batch_size = 32, validation_data = (val_x, val_y))\n",
        "        _, train_accuracy = model.evaluate(x_train, y_train)\n",
        "        print('Accuracy: %.2f' % (train_accuracy*100))\n",
        "        _, test_accuracy = model.evaluate(x_test, y_test)\n",
        "        print('Accuracy: %.2f' % (test_accuracy*100))\n",
        "        return (model,history,train_accuracy*100,test_accuracy*100)\n",
        "      def summary(self,m):\n",
        "        model=m[0]\n",
        "        model.summary()"
      ],
      "metadata": {
        "id": "4IZw6ZWwANN9"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = NN()"
      ],
      "metadata": {
        "id": "I-DXSAFAIePO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a=m.ADAM()\n",
        "m.summary(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWhgS4xBJIk-",
        "outputId": "69215230-e3fb-48e7-81ab-22354a8cd807"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 40s 24ms/step - loss: 1.8628 - accuracy: 0.3530 - val_loss: 1.3644 - val_accuracy: 0.5013\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.3260 - accuracy: 0.5233 - val_loss: 1.6093 - val_accuracy: 0.4675\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 1.0933 - accuracy: 0.6167 - val_loss: 0.9309 - val_accuracy: 0.6679\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.9690 - accuracy: 0.6660 - val_loss: 0.7539 - val_accuracy: 0.7326\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.8832 - accuracy: 0.6987 - val_loss: 0.7271 - val_accuracy: 0.7516\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.8175 - accuracy: 0.7221 - val_loss: 0.6347 - val_accuracy: 0.7775\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7595 - accuracy: 0.7434 - val_loss: 0.6659 - val_accuracy: 0.7615\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.7193 - accuracy: 0.7571 - val_loss: 0.5597 - val_accuracy: 0.7996\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 38s 24ms/step - loss: 0.6838 - accuracy: 0.7707 - val_loss: 0.5176 - val_accuracy: 0.8239\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 38s 25ms/step - loss: 0.6477 - accuracy: 0.7822 - val_loss: 0.4751 - val_accuracy: 0.8405\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4817 - accuracy: 0.8350\n",
            "Accuracy: 83.50\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.6153 - accuracy: 0.7898\n",
            "Accuracy: 78.98\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_42 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_55 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_34 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_56 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_57 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_35 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_58 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_59 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_36 (Dropout)        (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_60 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_61 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_37 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_62 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_38 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 579,274\n",
            "Trainable params: 577,610\n",
            "Non-trainable params: 1,664\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = m.RMS()\n",
        "m.summary(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VIpzEH7JMby",
        "outputId": "7bbc6057-174a-475a-e4a1-8d99301de8ec"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 46s 28ms/step - loss: 1.9038 - accuracy: 0.3266 - val_loss: 1.3658 - val_accuracy: 0.4995\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 1.2980 - accuracy: 0.5441 - val_loss: 1.0994 - val_accuracy: 0.5975\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 1.1008 - accuracy: 0.6245 - val_loss: 0.8781 - val_accuracy: 0.6848\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 42s 27ms/step - loss: 0.9875 - accuracy: 0.6716 - val_loss: 0.9641 - val_accuracy: 0.6722\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.9062 - accuracy: 0.7043 - val_loss: 0.7726 - val_accuracy: 0.7320\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.8402 - accuracy: 0.7268 - val_loss: 0.7876 - val_accuracy: 0.7387\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.7914 - accuracy: 0.7450 - val_loss: 0.5908 - val_accuracy: 0.7995\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.7526 - accuracy: 0.7629 - val_loss: 0.5275 - val_accuracy: 0.8243\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 43s 28ms/step - loss: 0.7073 - accuracy: 0.7773 - val_loss: 0.5252 - val_accuracy: 0.8182\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 43s 27ms/step - loss: 0.6787 - accuracy: 0.7869 - val_loss: 0.4779 - val_accuracy: 0.8402\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.4757 - accuracy: 0.8397\n",
            "Accuracy: 83.97\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6368 - accuracy: 0.7903\n",
            "Accuracy: 79.03\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_48 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_64 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_65 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_66 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_67 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_68 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_69 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_70 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_71 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 725,866\n",
            "Trainable params: 723,882\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = m.SGD()\n",
        "m.summary(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdSaTSDcTRg3",
        "outputId": "d0b93bdf-49b8-4156-c4fd-e4306cf40aa1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 28s 33ms/step - loss: 2.3576 - accuracy: 0.2240 - val_loss: 1.8103 - val_accuracy: 0.3346\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.8178 - accuracy: 0.3242 - val_loss: 1.8090 - val_accuracy: 0.3478\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 1.6726 - accuracy: 0.3733 - val_loss: 1.7008 - val_accuracy: 0.3764\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.5910 - accuracy: 0.4086 - val_loss: 1.6288 - val_accuracy: 0.4086\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.5258 - accuracy: 0.4370 - val_loss: 1.4161 - val_accuracy: 0.4834\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.4556 - accuracy: 0.4643 - val_loss: 1.3856 - val_accuracy: 0.4908\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.3980 - accuracy: 0.4911 - val_loss: 1.4456 - val_accuracy: 0.4656\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 1.3423 - accuracy: 0.5112 - val_loss: 1.2382 - val_accuracy: 0.5492\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 1.2930 - accuracy: 0.5347 - val_loss: 1.2721 - val_accuracy: 0.5524\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.2426 - accuracy: 0.5536 - val_loss: 1.0901 - val_accuracy: 0.6049\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0935 - accuracy: 0.6004\n",
            "Accuracy: 60.04\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 1.1242 - accuracy: 0.5928\n",
            "Accuracy: 59.28\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_48 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_63 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_39 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_49 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_64 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_50 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_65 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_40 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_51 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_66 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_52 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_67 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_41 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_53 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_68 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_69 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_42 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_70 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_43 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_71 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_44 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 725,866\n",
            "Trainable params: 723,882\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = m.SGD_2()\n",
        "m.summary(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LCefxpFeM-i",
        "outputId": "dd00e8d4-02b2-4c9f-eca2-9c4fb26d9029"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 40s 49ms/step - loss: 2.3717 - accuracy: 0.2169 - val_loss: 1.8902 - val_accuracy: 0.2828\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.8261 - accuracy: 0.3218 - val_loss: 1.8113 - val_accuracy: 0.3578\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 1.6723 - accuracy: 0.3788 - val_loss: 1.6942 - val_accuracy: 0.3765\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 1.5936 - accuracy: 0.4131 - val_loss: 1.7039 - val_accuracy: 0.3965\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.5275 - accuracy: 0.4392 - val_loss: 1.4167 - val_accuracy: 0.4772\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 37s 47ms/step - loss: 1.4740 - accuracy: 0.4636 - val_loss: 1.3051 - val_accuracy: 0.5167\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.4162 - accuracy: 0.4878 - val_loss: 1.3321 - val_accuracy: 0.5290\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.3680 - accuracy: 0.5070 - val_loss: 1.2476 - val_accuracy: 0.5378\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.3197 - accuracy: 0.5285 - val_loss: 1.1467 - val_accuracy: 0.5841\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.2693 - accuracy: 0.5460 - val_loss: 1.1156 - val_accuracy: 0.5981\n",
            "1563/1563 [==============================] - 12s 7ms/step - loss: 1.1233 - accuracy: 0.5982\n",
            "Accuracy: 59.82\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 1.1535 - accuracy: 0.5879\n",
            "Accuracy: 58.79\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_59 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_80 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_51 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_60 (Conv2D)          (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_81 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_52 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_61 (Conv2D)          (None, 32, 32, 128)       65664     \n",
            "                                                                 \n",
            " batch_normalization_82 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_53 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_62 (Conv2D)          (None, 32, 32, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_83 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_29 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_63 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_84 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_54 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_64 (Conv2D)          (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_85 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 8, 8, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 256)               524544    \n",
            "                                                                 \n",
            " batch_normalization_86 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_55 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_87 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_56 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_88 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_57 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 922,474\n",
            "Trainable params: 920,490\n",
            "Non-trainable params: 1,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "e=m.ADAM_2()\n",
        "m.summary(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrlUnTf9eSKD",
        "outputId": "3f688c00-56f4-4c32-fe04-0230328591a7"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 41s 25ms/step - loss: 2.0025 - accuracy: 0.2873 - val_loss: 1.5495 - val_accuracy: 0.4435\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.5089 - accuracy: 0.4497 - val_loss: 1.3398 - val_accuracy: 0.5024\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.2827 - accuracy: 0.5466 - val_loss: 1.3437 - val_accuracy: 0.5118\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.1319 - accuracy: 0.6101 - val_loss: 1.0644 - val_accuracy: 0.6122\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 1.0343 - accuracy: 0.6488 - val_loss: 0.8578 - val_accuracy: 0.6992\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9560 - accuracy: 0.6798 - val_loss: 1.0085 - val_accuracy: 0.6545\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.9015 - accuracy: 0.6980 - val_loss: 0.6691 - val_accuracy: 0.7693\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8537 - accuracy: 0.7191 - val_loss: 0.6978 - val_accuracy: 0.7664\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.8105 - accuracy: 0.7352 - val_loss: 0.6617 - val_accuracy: 0.7703\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 39s 25ms/step - loss: 0.7784 - accuracy: 0.7445 - val_loss: 0.6694 - val_accuracy: 0.7670\n",
            "1563/1563 [==============================] - 12s 8ms/step - loss: 0.6723 - accuracy: 0.7667\n",
            "Accuracy: 76.67\n",
            "313/313 [==============================] - 2s 8ms/step - loss: 0.7826 - accuracy: 0.7356\n",
            "Accuracy: 73.56\n",
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_65 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_89 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_58 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_66 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_90 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_67 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_59 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_68 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_92 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_69 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_60 (Dropout)        (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " conv2d_70 (Conv2D)          (None, 8, 8, 32)          9248      \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 8, 8, 32)         128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_33 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_61 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_62 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_63 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 587,146\n",
            "Trainable params: 585,354\n",
            "Non-trainable params: 1,792\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=m.RMS_2()\n",
        "m.summary(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zU_4CdBeZ3M",
        "outputId": "617f337f-54a7-40fc-cb53-2fcc4af6d748"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 41s 48ms/step - loss: 2.0215 - accuracy: 0.2972 - val_loss: 1.8234 - val_accuracy: 0.3598\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 1.3523 - accuracy: 0.5183 - val_loss: 1.2288 - val_accuracy: 0.5559\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 1.1182 - accuracy: 0.6130 - val_loss: 1.3296 - val_accuracy: 0.5613\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.9827 - accuracy: 0.6693 - val_loss: 0.8904 - val_accuracy: 0.6854\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.8958 - accuracy: 0.7042 - val_loss: 0.7246 - val_accuracy: 0.7467\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.8275 - accuracy: 0.7291 - val_loss: 0.8075 - val_accuracy: 0.7205\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.7733 - accuracy: 0.7498 - val_loss: 0.6111 - val_accuracy: 0.7906\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.7269 - accuracy: 0.7673 - val_loss: 0.5928 - val_accuracy: 0.8001\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 36s 46ms/step - loss: 0.6815 - accuracy: 0.7831 - val_loss: 0.5326 - val_accuracy: 0.8229\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 36s 45ms/step - loss: 0.6539 - accuracy: 0.7947 - val_loss: 0.5235 - val_accuracy: 0.8222\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 0.5306 - accuracy: 0.8190\n",
            "Accuracy: 81.90\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 0.6788 - accuracy: 0.7718\n",
            "Accuracy: 77.18\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_71 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_64 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_72 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 32, 32, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_34 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_73 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 16, 16, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_65 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_74 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_35 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_75 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_66 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_76 (Conv2D)          (None, 8, 8, 64)          16448     \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_67 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_77 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_104 (Ba  (None, 8, 8, 32)         128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_36 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_12 (Flatten)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_105 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_68 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_106 (Ba  (None, 128)              512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_69 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_107 (Ba  (None, 64)               256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_70 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 742,570\n",
            "Trainable params: 740,458\n",
            "Non-trainable params: 2,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g=m.ADAGRAD()\n",
        "m.summary(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yhSuk0OepWz",
        "outputId": "ccdcdc37-1aaa-45a9-9f4e-6428f15cf4d3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 38s 47ms/step - loss: 3.2017 - accuracy: 0.1254 - val_loss: 2.3170 - val_accuracy: 0.1631\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 2.8457 - accuracy: 0.1588 - val_loss: 2.1957 - val_accuracy: 0.1951\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 2.6767 - accuracy: 0.1791 - val_loss: 2.1538 - val_accuracy: 0.2024\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 2.5428 - accuracy: 0.1957 - val_loss: 2.1031 - val_accuracy: 0.2138\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 2.4636 - accuracy: 0.2067 - val_loss: 2.0724 - val_accuracy: 0.2220\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 2.3791 - accuracy: 0.2192 - val_loss: 2.0008 - val_accuracy: 0.2359\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 2.3292 - accuracy: 0.2225 - val_loss: 1.9672 - val_accuracy: 0.2492\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 35s 44ms/step - loss: 2.2804 - accuracy: 0.2314 - val_loss: 1.9519 - val_accuracy: 0.2556\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 2.2313 - accuracy: 0.2385 - val_loss: 1.9202 - val_accuracy: 0.2658\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 35s 45ms/step - loss: 2.1932 - accuracy: 0.2456 - val_loss: 1.9103 - val_accuracy: 0.2709\n",
            "1563/1563 [==============================] - 13s 8ms/step - loss: 1.9071 - accuracy: 0.2751\n",
            "Accuracy: 27.51\n",
            "313/313 [==============================] - 3s 8ms/step - loss: 1.8992 - accuracy: 0.2770\n",
            "Accuracy: 27.70\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_78 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_108 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_71 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_79 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_109 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_37 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_80 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_110 (Ba  (None, 16, 16, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_72 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_81 (Conv2D)          (None, 16, 16, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_111 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_38 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_82 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_112 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_73 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_83 (Conv2D)          (None, 8, 8, 64)          16448     \n",
            "                                                                 \n",
            " batch_normalization_113 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_74 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_84 (Conv2D)          (None, 8, 8, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_114 (Ba  (None, 8, 8, 32)         128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_39 (MaxPoolin  (None, 4, 4, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_13 (Flatten)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " batch_normalization_115 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_75 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_116 (Ba  (None, 128)              512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_76 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_117 (Ba  (None, 64)               256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_77 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 742,570\n",
            "Trainable params: 740,458\n",
            "Non-trainable params: 2,112\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h=m.ADAGRAD_2()\n",
        "m.summary(h)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7GIWFwsesgG",
        "outputId": "5abd37fe-56a0-44c0-b7d8-b5e0671c974f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 41s 50ms/step - loss: 3.1287 - accuracy: 0.1277 - val_loss: 2.2583 - val_accuracy: 0.1654\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 2.8076 - accuracy: 0.1512 - val_loss: 2.1383 - val_accuracy: 0.2016\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.6550 - accuracy: 0.1681 - val_loss: 2.0836 - val_accuracy: 0.2221\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.5548 - accuracy: 0.1816 - val_loss: 2.0598 - val_accuracy: 0.2239\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.4605 - accuracy: 0.1918 - val_loss: 2.0043 - val_accuracy: 0.2385\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.3876 - accuracy: 0.2040 - val_loss: 1.9749 - val_accuracy: 0.2457\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.3456 - accuracy: 0.2092 - val_loss: 1.9441 - val_accuracy: 0.2551\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 2.2753 - accuracy: 0.2218 - val_loss: 1.9414 - val_accuracy: 0.2541\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 2.2440 - accuracy: 0.2239 - val_loss: 1.9280 - val_accuracy: 0.2521\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 38s 49ms/step - loss: 2.2068 - accuracy: 0.2310 - val_loss: 1.9155 - val_accuracy: 0.2627\n",
            "1563/1563 [==============================] - 14s 9ms/step - loss: 1.9156 - accuracy: 0.2648\n",
            "Accuracy: 26.48\n",
            "313/313 [==============================] - 3s 9ms/step - loss: 1.9190 - accuracy: 0.2688\n",
            "Accuracy: 26.88\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_85 (Conv2D)          (None, 32, 32, 128)       9728      \n",
            "                                                                 \n",
            " batch_normalization_118 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_78 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_86 (Conv2D)          (None, 32, 32, 128)       262272    \n",
            "                                                                 \n",
            " batch_normalization_119 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_40 (MaxPoolin  (None, 16, 16, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_87 (Conv2D)          (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_120 (Ba  (None, 16, 16, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_79 (Dropout)        (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_88 (Conv2D)          (None, 16, 16, 64)        131136    \n",
            "                                                                 \n",
            " batch_normalization_121 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_41 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_89 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_122 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_42 (MaxPoolin  (None, 4, 4, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_90 (Conv2D)          (None, 4, 4, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_123 (Ba  (None, 4, 4, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_80 (Dropout)        (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_91 (Conv2D)          (None, 4, 4, 64)          16448     \n",
            "                                                                 \n",
            " batch_normalization_124 (Ba  (None, 4, 4, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_81 (Dropout)        (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_92 (Conv2D)          (None, 4, 4, 32)          18464     \n",
            "                                                                 \n",
            " batch_normalization_125 (Ba  (None, 4, 4, 32)         128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_43 (MaxPoolin  (None, 2, 2, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_14 (Flatten)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " batch_normalization_126 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_82 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_127 (Ba  (None, 128)              512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_83 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_128 (Ba  (None, 64)               256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_84 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 738,794\n",
            "Trainable params: 736,554\n",
            "Non-trainable params: 2,240\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=m.SGD_3()\n",
        "m.summary(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5I_5gO2TezLx",
        "outputId": "3bfe10d5-d8c9-4eda-a637-a72601b6a9e7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 69s 84ms/step - loss: 2.5510 - accuracy: 0.1245 - val_loss: 2.2081 - val_accuracy: 0.1930\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 2.2262 - accuracy: 0.1613 - val_loss: 2.1013 - val_accuracy: 0.2392\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 2.1165 - accuracy: 0.1920 - val_loss: 2.0557 - val_accuracy: 0.2590\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 2.0378 - accuracy: 0.2104 - val_loss: 1.9740 - val_accuracy: 0.2635\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 1.9833 - accuracy: 0.2223 - val_loss: 1.8958 - val_accuracy: 0.2564\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 1.9496 - accuracy: 0.2271 - val_loss: 1.8246 - val_accuracy: 0.2866\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 1.9220 - accuracy: 0.2393 - val_loss: 1.8062 - val_accuracy: 0.3121\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 64s 81ms/step - loss: 1.9028 - accuracy: 0.2472 - val_loss: 1.7964 - val_accuracy: 0.3020\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 63s 81ms/step - loss: 1.8824 - accuracy: 0.2553 - val_loss: 1.7637 - val_accuracy: 0.3125\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 64s 82ms/step - loss: 1.8605 - accuracy: 0.2652 - val_loss: 1.7696 - val_accuracy: 0.3190\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.7714 - accuracy: 0.3197\n",
            "Accuracy: 31.97\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.7705 - accuracy: 0.3147\n",
            "Accuracy: 31.47\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_93 (Conv2D)          (None, 32, 32, 256)       19456     \n",
            "                                                                 \n",
            " batch_normalization_129 (Ba  (None, 32, 32, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_85 (Dropout)        (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_94 (Conv2D)          (None, 32, 32, 128)       819328    \n",
            "                                                                 \n",
            " batch_normalization_130 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_86 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_95 (Conv2D)          (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_131 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_87 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_96 (Conv2D)          (None, 32, 32, 128)       65664     \n",
            "                                                                 \n",
            " batch_normalization_132 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_88 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_97 (Conv2D)          (None, 32, 32, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_133 (Ba  (None, 32, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_44 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_98 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_134 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_89 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_99 (Conv2D)          (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_135 (Ba  (None, 16, 16, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_45 (MaxPoolin  (None, 8, 8, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_15 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_51 (Dense)            (None, 256)               524544    \n",
            "                                                                 \n",
            " batch_normalization_136 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_90 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_137 (Ba  (None, 128)              512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_91 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_138 (Ba  (None, 64)               256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_92 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_54 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_139 (Ba  (None, 32)               128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_93 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " batch_normalization_140 (Ba  (None, 16)               64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_94 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,754,874\n",
            "Trainable params: 1,752,282\n",
            "Non-trainable params: 2,592\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "j=m.ADAM_3()\n",
        "m.summary(j)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6Iy3rHDe4as",
        "outputId": "f662710d-f44f-4389-feef-c78fbc0cfbc0"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1563/1563 [==============================] - 71s 43ms/step - loss: 2.3330 - accuracy: 0.1508 - val_loss: 1.9361 - val_accuracy: 0.2640\n",
            "Epoch 2/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.9341 - accuracy: 0.2397 - val_loss: 1.9618 - val_accuracy: 0.2481\n",
            "Epoch 3/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7969 - accuracy: 0.3002 - val_loss: 1.5598 - val_accuracy: 0.4058\n",
            "Epoch 4/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.7006 - accuracy: 0.3461 - val_loss: 1.5839 - val_accuracy: 0.3798\n",
            "Epoch 5/10\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 1.6307 - accuracy: 0.3788 - val_loss: 1.4096 - val_accuracy: 0.4570\n",
            "Epoch 6/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.5566 - accuracy: 0.4133 - val_loss: 1.3637 - val_accuracy: 0.4951\n",
            "Epoch 7/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.5177 - accuracy: 0.4375 - val_loss: 1.1898 - val_accuracy: 0.5648\n",
            "Epoch 8/10\n",
            "1563/1563 [==============================] - 67s 43ms/step - loss: 1.4451 - accuracy: 0.4697 - val_loss: 1.0995 - val_accuracy: 0.6040\n",
            "Epoch 9/10\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 1.3979 - accuracy: 0.4927 - val_loss: 1.0594 - val_accuracy: 0.6289\n",
            "Epoch 10/10\n",
            "1563/1563 [==============================] - 69s 44ms/step - loss: 1.3470 - accuracy: 0.5206 - val_loss: 1.0206 - val_accuracy: 0.6424\n",
            "1563/1563 [==============================] - 18s 12ms/step - loss: 1.0235 - accuracy: 0.6436\n",
            "Accuracy: 64.36\n",
            "313/313 [==============================] - 4s 12ms/step - loss: 1.0814 - accuracy: 0.6207\n",
            "Accuracy: 62.07\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_100 (Conv2D)         (None, 32, 32, 256)       19456     \n",
            "                                                                 \n",
            " batch_normalization_141 (Ba  (None, 32, 32, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_95 (Dropout)        (None, 32, 32, 256)       0         \n",
            "                                                                 \n",
            " conv2d_101 (Conv2D)         (None, 32, 32, 128)       819328    \n",
            "                                                                 \n",
            " batch_normalization_142 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_96 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_102 (Conv2D)         (None, 32, 32, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_143 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_97 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 32, 32, 128)       65664     \n",
            "                                                                 \n",
            " batch_normalization_144 (Ba  (None, 32, 32, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_98 (Dropout)        (None, 32, 32, 128)       0         \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 32, 32, 64)        73792     \n",
            "                                                                 \n",
            " batch_normalization_145 (Ba  (None, 32, 32, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_46 (MaxPoolin  (None, 16, 16, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_146 (Ba  (None, 16, 16, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_99 (Dropout)        (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_147 (Ba  (None, 16, 16, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_47 (MaxPoolin  (None, 8, 8, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_16 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_57 (Dense)            (None, 256)               524544    \n",
            "                                                                 \n",
            " batch_normalization_148 (Ba  (None, 256)              1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_100 (Dropout)       (None, 256)               0         \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_149 (Ba  (None, 128)              512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_101 (Dropout)       (None, 128)               0         \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_150 (Ba  (None, 64)               256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_102 (Dropout)       (None, 64)                0         \n",
            "                                                                 \n",
            " dense_60 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " batch_normalization_151 (Ba  (None, 32)               128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_103 (Dropout)       (None, 32)                0         \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " batch_normalization_152 (Ba  (None, 16)               64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " dropout_104 (Dropout)       (None, 16)                0         \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 10)                170       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,754,874\n",
            "Trainable params: 1,752,282\n",
            "Non-trainable params: 2,592\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import *\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(32,32, 3)), \n",
        "    layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "model = Sequential([\n",
        "  #data_augumentation,\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(128, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(64, activation='relu'),\n",
        "  layers.Dense(132, activation='relu'),\n",
        "  layers.Dense(10,activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=\"sparse_categorical_crossentropy\",\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "model.fit(x_train,y_train, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz3W_gqie6_b",
        "outputId": "eff17a8f-1c22-4cc8-927e-32d899afcccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 28s 33ms/step - loss: 2.3636 - accuracy: 0.2209 - val_loss: 1.7818 - val_accuracy: 0.3569\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 1.8168 - accuracy: 0.3304 - val_loss: 1.6104 - val_accuracy: 0.4063\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.6598 - accuracy: 0.3843 - val_loss: 1.7160 - val_accuracy: 0.3875\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 25s 32ms/step - loss: 1.5697 - accuracy: 0.4228 - val_loss: 1.4595 - val_accuracy: 0.4687\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 25s 31ms/step - loss: 1.5085 - accuracy: 0.4474 - val_loss: 1.5457 - val_accuracy: 0.4448\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 24s 31ms/step - loss: 1.4572 - accuracy: 0.4701 - val_loss: 1.5284 - val_accuracy: 0.4500\n",
            "Epoch 7/10\n",
            "399/782 [==============>...............] - ETA: 11s - loss: 1.4177 - accuracy: 0.4848"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tensorflow --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XqcIv6RexKiC",
        "outputId": "5e3bc731-0fe2-41b8-dd6c-d80b768debef"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
            "\u001b[K     || 578.0 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Collecting keras<2.11,>=2.10.0\n",
            "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     || 1.7 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
            "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[K     || 438 kB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Collecting tensorboard<2.11,>=2.10\n",
            "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
            "\u001b[K     || 5.9 MB 51.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.10.26-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.10.26 keras-2.10.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "22ngBd_b0mD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}