{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "371bf38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\datasc\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\envs\\datasc\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\envs\\datasc\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import  backend as K\n",
    "from keras.datasets import mnist\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adagrad\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e2a2473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "id = 7\n",
    "image = np.array(x_train[id], dtype='float')\n",
    "pixels = image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "# print(X_train[id])\n",
    "print(y_train[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "228c07be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#herre we need to one hot encoding since out of the 10 available outputs only one is the answer\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ee0cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = x_train.shape[1]\n",
    "input_size = image_size*image_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4cddd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reszing\n",
    "x_train = np.reshape(x_train, [-1, input_size])\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = np.reshape(x_test, [-1, input_size])\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9919909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statistics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x,val_x,train_y,val_y = train_test_split(x_train, y_train, test_size=0.16,random_state=10)\n",
    "#making our model with adam optimizer as shown in the previouus ipynb file sniec it gives the best accuracy(validation)\n",
    "#now tuning it with more lauyers different activation functions etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5c3d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "742/742 - 28s - loss: 1.2058 - accuracy: 0.5301 - val_loss: 0.3712 - val_accuracy: 0.9054\n",
      "Epoch 2/100\n",
      "742/742 - 6s - loss: 0.4853 - accuracy: 0.8619 - val_loss: 0.2399 - val_accuracy: 0.9371\n",
      "Epoch 3/100\n",
      "742/742 - 6s - loss: 0.3373 - accuracy: 0.9129 - val_loss: 0.2033 - val_accuracy: 0.9492\n",
      "Epoch 4/100\n",
      "742/742 - 6s - loss: 0.2830 - accuracy: 0.9264 - val_loss: 0.1727 - val_accuracy: 0.9523\n",
      "Epoch 5/100\n",
      "742/742 - 6s - loss: 0.2490 - accuracy: 0.9367 - val_loss: 0.1604 - val_accuracy: 0.9579\n",
      "Epoch 6/100\n",
      "742/742 - 6s - loss: 0.2321 - accuracy: 0.9410 - val_loss: 0.1634 - val_accuracy: 0.9585\n",
      "Epoch 7/100\n",
      "742/742 - 6s - loss: 0.2139 - accuracy: 0.9448 - val_loss: 0.1623 - val_accuracy: 0.9575\n",
      "Epoch 8/100\n",
      "742/742 - 6s - loss: 0.2035 - accuracy: 0.9484 - val_loss: 0.1570 - val_accuracy: 0.9591\n",
      "Epoch 9/100\n",
      "742/742 - 6s - loss: 0.1976 - accuracy: 0.9507 - val_loss: 0.1485 - val_accuracy: 0.9639\n",
      "Epoch 10/100\n",
      "742/742 - 6s - loss: 0.1861 - accuracy: 0.9536 - val_loss: 0.1459 - val_accuracy: 0.9636\n",
      "Epoch 11/100\n",
      "742/742 - 6s - loss: 0.1875 - accuracy: 0.9538 - val_loss: 0.1437 - val_accuracy: 0.9666\n",
      "Epoch 12/100\n",
      "742/742 - 6s - loss: 0.1852 - accuracy: 0.9558 - val_loss: 0.1546 - val_accuracy: 0.9631\n",
      "Epoch 13/100\n",
      "742/742 - 6s - loss: 0.1763 - accuracy: 0.9581 - val_loss: 0.1444 - val_accuracy: 0.9655\n",
      "Epoch 14/100\n",
      "742/742 - 6s - loss: 0.1770 - accuracy: 0.9573 - val_loss: 0.1346 - val_accuracy: 0.9681\n",
      "Epoch 15/100\n",
      "742/742 - 6s - loss: 0.1766 - accuracy: 0.9590 - val_loss: 0.1457 - val_accuracy: 0.9648\n",
      "Epoch 16/100\n",
      "742/742 - 6s - loss: 0.1803 - accuracy: 0.9572 - val_loss: 0.1415 - val_accuracy: 0.9665\n",
      "Epoch 17/100\n",
      "742/742 - 6s - loss: 0.1714 - accuracy: 0.9594 - val_loss: 0.1369 - val_accuracy: 0.9650\n",
      "Epoch 18/100\n",
      "742/742 - 6s - loss: 0.1619 - accuracy: 0.9625 - val_loss: 0.1392 - val_accuracy: 0.9684\n",
      "Epoch 19/100\n",
      "742/742 - 6s - loss: 0.1686 - accuracy: 0.9612 - val_loss: 0.1515 - val_accuracy: 0.9663\n",
      "Epoch 20/100\n",
      "742/742 - 6s - loss: 0.1563 - accuracy: 0.9638 - val_loss: 0.1526 - val_accuracy: 0.9668\n",
      "Epoch 21/100\n",
      "742/742 - 6s - loss: 0.1553 - accuracy: 0.9639 - val_loss: 0.1365 - val_accuracy: 0.9701\n",
      "Epoch 22/100\n",
      "742/742 - 6s - loss: 0.1538 - accuracy: 0.9637 - val_loss: 0.1456 - val_accuracy: 0.9693\n",
      "Epoch 23/100\n",
      "742/742 - 6s - loss: 0.1603 - accuracy: 0.9641 - val_loss: 0.1454 - val_accuracy: 0.9675\n",
      "Epoch 24/100\n",
      "742/742 - 6s - loss: 0.1497 - accuracy: 0.9655 - val_loss: 0.1414 - val_accuracy: 0.9684\n",
      "Epoch 25/100\n",
      "742/742 - 6s - loss: 0.1508 - accuracy: 0.9648 - val_loss: 0.1421 - val_accuracy: 0.9703\n",
      "Epoch 26/100\n",
      "742/742 - 6s - loss: 0.1494 - accuracy: 0.9675 - val_loss: 0.1399 - val_accuracy: 0.9694\n",
      "Epoch 27/100\n",
      "742/742 - 6s - loss: 0.1546 - accuracy: 0.9661 - val_loss: 0.1576 - val_accuracy: 0.9686\n",
      "Epoch 28/100\n",
      "742/742 - 6s - loss: 0.1463 - accuracy: 0.9677 - val_loss: 0.1397 - val_accuracy: 0.9683\n",
      "Epoch 29/100\n",
      "742/742 - 6s - loss: 0.1462 - accuracy: 0.9675 - val_loss: 0.1576 - val_accuracy: 0.9699\n",
      "Epoch 30/100\n",
      "742/742 - 6s - loss: 0.1510 - accuracy: 0.9655 - val_loss: 0.1542 - val_accuracy: 0.9664\n",
      "Epoch 31/100\n",
      "742/742 - 6s - loss: 0.1505 - accuracy: 0.9669 - val_loss: 0.1407 - val_accuracy: 0.9688\n",
      "Epoch 32/100\n",
      "742/742 - 6s - loss: 0.1458 - accuracy: 0.9681 - val_loss: 0.1497 - val_accuracy: 0.9692\n",
      "Epoch 33/100\n",
      "742/742 - 6s - loss: 0.1457 - accuracy: 0.9681 - val_loss: 0.1407 - val_accuracy: 0.9689\n",
      "Epoch 34/100\n",
      "742/742 - 6s - loss: 0.1436 - accuracy: 0.9693 - val_loss: 0.1513 - val_accuracy: 0.9714\n",
      "Epoch 35/100\n",
      "742/742 - 6s - loss: 0.1401 - accuracy: 0.9697 - val_loss: 0.1439 - val_accuracy: 0.9698\n",
      "Epoch 36/100\n",
      "742/742 - 6s - loss: 0.1403 - accuracy: 0.9692 - val_loss: 0.1578 - val_accuracy: 0.9681\n",
      "Epoch 37/100\n",
      "742/742 - 6s - loss: 0.1519 - accuracy: 0.9675 - val_loss: 0.1625 - val_accuracy: 0.9689\n",
      "Epoch 38/100\n",
      "742/742 - 6s - loss: 0.1430 - accuracy: 0.9687 - val_loss: 0.1615 - val_accuracy: 0.9700\n",
      "Epoch 39/100\n",
      "742/742 - 5s - loss: 0.1465 - accuracy: 0.9682 - val_loss: 0.1584 - val_accuracy: 0.9712\n",
      "Epoch 40/100\n",
      "742/742 - 6s - loss: 0.1460 - accuracy: 0.9692 - val_loss: 0.1596 - val_accuracy: 0.9695\n",
      "Epoch 41/100\n",
      "742/742 - 6s - loss: 0.1416 - accuracy: 0.9699 - val_loss: 0.1627 - val_accuracy: 0.9698\n",
      "Epoch 42/100\n",
      "742/742 - 6s - loss: 0.1379 - accuracy: 0.9704 - val_loss: 0.1635 - val_accuracy: 0.9700\n",
      "Epoch 43/100\n",
      "742/742 - 6s - loss: 0.1463 - accuracy: 0.9692 - val_loss: 0.1563 - val_accuracy: 0.9688\n",
      "Epoch 44/100\n",
      "742/742 - 6s - loss: 0.1441 - accuracy: 0.9686 - val_loss: 0.1754 - val_accuracy: 0.9703\n",
      "Epoch 45/100\n",
      "742/742 - 6s - loss: 0.1476 - accuracy: 0.9696 - val_loss: 0.1500 - val_accuracy: 0.9692\n",
      "Epoch 46/100\n",
      "742/742 - 6s - loss: 0.1377 - accuracy: 0.9707 - val_loss: 0.1675 - val_accuracy: 0.9710\n",
      "Epoch 47/100\n",
      "742/742 - 6s - loss: 0.1353 - accuracy: 0.9707 - val_loss: 0.1661 - val_accuracy: 0.9706\n",
      "Epoch 48/100\n",
      "742/742 - 6s - loss: 0.1486 - accuracy: 0.9692 - val_loss: 0.1719 - val_accuracy: 0.9688\n",
      "Epoch 49/100\n",
      "742/742 - 6s - loss: 0.1493 - accuracy: 0.9687 - val_loss: 0.1754 - val_accuracy: 0.9688\n",
      "Epoch 50/100\n",
      "742/742 - 6s - loss: 0.1464 - accuracy: 0.9693 - val_loss: 0.1543 - val_accuracy: 0.9721\n",
      "Epoch 51/100\n",
      "742/742 - 6s - loss: 0.1389 - accuracy: 0.9703 - val_loss: 0.1597 - val_accuracy: 0.9711\n",
      "Epoch 52/100\n",
      "742/742 - 6s - loss: 0.1322 - accuracy: 0.9722 - val_loss: 0.1947 - val_accuracy: 0.9710\n",
      "Epoch 53/100\n",
      "742/742 - 6s - loss: 0.1454 - accuracy: 0.9708 - val_loss: 0.1596 - val_accuracy: 0.9706\n",
      "Epoch 54/100\n",
      "742/742 - 6s - loss: 0.1398 - accuracy: 0.9712 - val_loss: 0.1789 - val_accuracy: 0.9695\n",
      "Epoch 55/100\n",
      "742/742 - 6s - loss: 0.1476 - accuracy: 0.9707 - val_loss: 0.1744 - val_accuracy: 0.9694\n",
      "Epoch 56/100\n",
      "742/742 - 6s - loss: 0.1397 - accuracy: 0.9710 - val_loss: 0.1582 - val_accuracy: 0.9715\n",
      "Epoch 57/100\n",
      "742/742 - 6s - loss: 0.1401 - accuracy: 0.9711 - val_loss: 0.1593 - val_accuracy: 0.9698\n",
      "Epoch 58/100\n",
      "742/742 - 6s - loss: 0.1434 - accuracy: 0.9704 - val_loss: 0.1578 - val_accuracy: 0.9705\n",
      "Epoch 59/100\n",
      "742/742 - 6s - loss: 0.1386 - accuracy: 0.9710 - val_loss: 0.1705 - val_accuracy: 0.9675\n",
      "Epoch 60/100\n",
      "742/742 - 6s - loss: 0.1407 - accuracy: 0.9707 - val_loss: 0.1715 - val_accuracy: 0.9707\n",
      "Epoch 61/100\n",
      "742/742 - 6s - loss: 0.1402 - accuracy: 0.9706 - val_loss: 0.1624 - val_accuracy: 0.9701\n",
      "Epoch 62/100\n",
      "742/742 - 6s - loss: 0.1412 - accuracy: 0.9713 - val_loss: 0.1562 - val_accuracy: 0.9709\n",
      "Epoch 63/100\n",
      "742/742 - 6s - loss: 0.1368 - accuracy: 0.9725 - val_loss: 0.1574 - val_accuracy: 0.9733\n",
      "Epoch 64/100\n",
      "742/742 - 6s - loss: 0.1295 - accuracy: 0.9740 - val_loss: 0.1798 - val_accuracy: 0.9681\n",
      "Epoch 65/100\n",
      "742/742 - 6s - loss: 0.1378 - accuracy: 0.9724 - val_loss: 0.1865 - val_accuracy: 0.9689\n",
      "Epoch 66/100\n",
      "742/742 - 6s - loss: 0.1434 - accuracy: 0.9711 - val_loss: 0.1725 - val_accuracy: 0.9691\n",
      "Epoch 67/100\n",
      "742/742 - 6s - loss: 0.1402 - accuracy: 0.9729 - val_loss: 0.1705 - val_accuracy: 0.9728\n",
      "Epoch 68/100\n",
      "742/742 - 6s - loss: 0.1468 - accuracy: 0.9702 - val_loss: 0.1582 - val_accuracy: 0.9712\n",
      "Epoch 69/100\n",
      "742/742 - 6s - loss: 0.1341 - accuracy: 0.9730 - val_loss: 0.1781 - val_accuracy: 0.9704\n",
      "Epoch 70/100\n",
      "742/742 - 6s - loss: 0.1446 - accuracy: 0.9705 - val_loss: 0.1738 - val_accuracy: 0.9708\n",
      "Epoch 71/100\n",
      "742/742 - 6s - loss: 0.1495 - accuracy: 0.9701 - val_loss: 0.1666 - val_accuracy: 0.9710\n",
      "Epoch 72/100\n",
      "742/742 - 6s - loss: 0.1477 - accuracy: 0.9709 - val_loss: 0.1732 - val_accuracy: 0.9705\n",
      "Epoch 73/100\n",
      "742/742 - 6s - loss: 0.1555 - accuracy: 0.9698 - val_loss: 0.1697 - val_accuracy: 0.9699\n",
      "Epoch 74/100\n",
      "742/742 - 6s - loss: 0.1484 - accuracy: 0.9704 - val_loss: 0.1755 - val_accuracy: 0.9694\n",
      "Epoch 75/100\n",
      "742/742 - 6s - loss: 0.1521 - accuracy: 0.9691 - val_loss: 0.1636 - val_accuracy: 0.9704\n",
      "Epoch 76/100\n",
      "742/742 - 6s - loss: 0.1418 - accuracy: 0.9721 - val_loss: 0.1730 - val_accuracy: 0.9696\n",
      "Epoch 77/100\n",
      "742/742 - 6s - loss: 0.1465 - accuracy: 0.9709 - val_loss: 0.1752 - val_accuracy: 0.9707\n",
      "Epoch 78/100\n",
      "742/742 - 6s - loss: 0.1432 - accuracy: 0.9714 - val_loss: 0.1786 - val_accuracy: 0.9682\n",
      "Epoch 79/100\n",
      "742/742 - 5s - loss: 0.1399 - accuracy: 0.9715 - val_loss: 0.1696 - val_accuracy: 0.9728\n",
      "Epoch 80/100\n",
      "742/742 - 6s - loss: 0.1443 - accuracy: 0.9712 - val_loss: 0.1623 - val_accuracy: 0.9707\n",
      "Epoch 81/100\n",
      "742/742 - 6s - loss: 0.1429 - accuracy: 0.9723 - val_loss: 0.1664 - val_accuracy: 0.9707\n",
      "Epoch 82/100\n",
      "742/742 - 6s - loss: 0.1463 - accuracy: 0.9716 - val_loss: 0.1742 - val_accuracy: 0.9689\n",
      "Epoch 83/100\n",
      "742/742 - 6s - loss: 0.1475 - accuracy: 0.9710 - val_loss: 0.1637 - val_accuracy: 0.9716\n",
      "Epoch 84/100\n",
      "742/742 - 6s - loss: 0.1354 - accuracy: 0.9727 - val_loss: 0.1705 - val_accuracy: 0.9727\n",
      "Epoch 85/100\n",
      "742/742 - 6s - loss: 0.1494 - accuracy: 0.9707 - val_loss: 0.1715 - val_accuracy: 0.9710\n",
      "Epoch 86/100\n",
      "742/742 - 6s - loss: 0.1373 - accuracy: 0.9722 - val_loss: 0.1822 - val_accuracy: 0.9693\n",
      "Epoch 87/100\n",
      "742/742 - 6s - loss: 0.1406 - accuracy: 0.9715 - val_loss: 0.1616 - val_accuracy: 0.9726\n",
      "Epoch 88/100\n",
      "742/742 - 6s - loss: 0.1366 - accuracy: 0.9736 - val_loss: 0.1809 - val_accuracy: 0.9710\n",
      "Epoch 89/100\n",
      "742/742 - 6s - loss: 0.1445 - accuracy: 0.9717 - val_loss: 0.1797 - val_accuracy: 0.9722\n",
      "Epoch 90/100\n",
      "742/742 - 5s - loss: 0.1369 - accuracy: 0.9730 - val_loss: 0.1778 - val_accuracy: 0.9709\n",
      "Epoch 91/100\n",
      "742/742 - 6s - loss: 0.1396 - accuracy: 0.9722 - val_loss: 0.1647 - val_accuracy: 0.9703\n",
      "Epoch 92/100\n",
      "742/742 - 6s - loss: 0.1470 - accuracy: 0.9708 - val_loss: 0.1718 - val_accuracy: 0.9709\n",
      "Epoch 93/100\n",
      "742/742 - 6s - loss: 0.1491 - accuracy: 0.9720 - val_loss: 0.1611 - val_accuracy: 0.9715\n",
      "Epoch 94/100\n",
      "742/742 - 6s - loss: 0.1434 - accuracy: 0.9718 - val_loss: 0.1743 - val_accuracy: 0.9701\n",
      "Epoch 95/100\n",
      "742/742 - 6s - loss: 0.1469 - accuracy: 0.9713 - val_loss: 0.1661 - val_accuracy: 0.9702\n",
      "Epoch 96/100\n",
      "742/742 - 5s - loss: 0.1462 - accuracy: 0.9707 - val_loss: 0.1543 - val_accuracy: 0.9716\n",
      "Epoch 97/100\n",
      "742/742 - 6s - loss: 0.1400 - accuracy: 0.9721 - val_loss: 0.1659 - val_accuracy: 0.9714\n",
      "Epoch 98/100\n",
      "742/742 - 6s - loss: 0.1481 - accuracy: 0.9715 - val_loss: 0.1605 - val_accuracy: 0.9721\n",
      "Epoch 99/100\n",
      "742/742 - 6s - loss: 0.1376 - accuracy: 0.9726 - val_loss: 0.1728 - val_accuracy: 0.9711\n",
      "Epoch 100/100\n",
      "742/742 - 6s - loss: 0.1444 - accuracy: 0.9716 - val_loss: 0.1795 - val_accuracy: 0.9684\n",
      "Accuracy: 96.10\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0778 - accuracy: 0.9841\n",
      "Accuracy: 98.41\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.9701\n",
      "Accuracy: 97.01\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(32, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.87, beta_2=0.991, epsilon=1e-07, amsgrad=False, name=\"Adam\"),metrics=['accuracy'])\n",
    "history_init = model.fit((train_x), (train_y),validation_data=((val_x),(val_y)),batch_size=68,epochs=100, verbose = 2)\n",
    "x = mean(history_init.history['accuracy'])\n",
    "print('Accuracy: %.2f' % (x*100))   \n",
    "_, accuracy = model.evaluate(x_train,y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))   \n",
    "_, accuracy = model.evaluate(x_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e516c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "742/742 - 6s - loss: 0.9213 - accuracy: 0.6886 - val_loss: 0.2912 - val_accuracy: 0.9296\n",
      "Epoch 2/100\n",
      "742/742 - 6s - loss: 0.4857 - accuracy: 0.8753 - val_loss: 0.2061 - val_accuracy: 0.9438\n",
      "Epoch 3/100\n",
      "742/742 - 6s - loss: 0.3454 - accuracy: 0.9149 - val_loss: 0.1794 - val_accuracy: 0.9501\n",
      "Epoch 4/100\n",
      "742/742 - 5s - loss: 0.2917 - accuracy: 0.9300 - val_loss: 0.1620 - val_accuracy: 0.9569\n",
      "Epoch 5/100\n",
      "742/742 - 6s - loss: 0.2582 - accuracy: 0.9376 - val_loss: 0.1512 - val_accuracy: 0.9592\n",
      "Epoch 6/100\n",
      "742/742 - 6s - loss: 0.2398 - accuracy: 0.9429 - val_loss: 0.1383 - val_accuracy: 0.9631\n",
      "Epoch 7/100\n",
      "742/742 - 6s - loss: 0.2211 - accuracy: 0.9451 - val_loss: 0.1610 - val_accuracy: 0.9559\n",
      "Epoch 8/100\n",
      "742/742 - 6s - loss: 0.2105 - accuracy: 0.9497 - val_loss: 0.1540 - val_accuracy: 0.9598\n",
      "Epoch 9/100\n",
      "742/742 - 6s - loss: 0.2071 - accuracy: 0.9507 - val_loss: 0.1350 - val_accuracy: 0.9644\n",
      "Epoch 10/100\n",
      "742/742 - 6s - loss: 0.1916 - accuracy: 0.9529 - val_loss: 0.1415 - val_accuracy: 0.9659\n",
      "Epoch 11/100\n",
      "742/742 - 6s - loss: 0.1882 - accuracy: 0.9538 - val_loss: 0.1441 - val_accuracy: 0.9646\n",
      "Epoch 12/100\n",
      "742/742 - 6s - loss: 0.1762 - accuracy: 0.9572 - val_loss: 0.1361 - val_accuracy: 0.9657\n",
      "Epoch 13/100\n",
      "742/742 - 6s - loss: 0.1780 - accuracy: 0.9571 - val_loss: 0.1365 - val_accuracy: 0.9649\n",
      "Epoch 14/100\n",
      "742/742 - 6s - loss: 0.1726 - accuracy: 0.9580 - val_loss: 0.1368 - val_accuracy: 0.9647\n",
      "Epoch 15/100\n",
      "742/742 - 6s - loss: 0.1587 - accuracy: 0.9622 - val_loss: 0.1488 - val_accuracy: 0.9656\n",
      "Epoch 16/100\n",
      "742/742 - 6s - loss: 0.1598 - accuracy: 0.9622 - val_loss: 0.1383 - val_accuracy: 0.9651\n",
      "Epoch 17/100\n",
      "742/742 - 6s - loss: 0.1601 - accuracy: 0.9623 - val_loss: 0.1369 - val_accuracy: 0.9670\n",
      "Epoch 18/100\n",
      "742/742 - 6s - loss: 0.1646 - accuracy: 0.9621 - val_loss: 0.1453 - val_accuracy: 0.9646\n",
      "Epoch 19/100\n",
      "742/742 - 6s - loss: 0.1551 - accuracy: 0.9627 - val_loss: 0.1450 - val_accuracy: 0.9657\n",
      "Epoch 20/100\n",
      "742/742 - 5s - loss: 0.1565 - accuracy: 0.9629 - val_loss: 0.1467 - val_accuracy: 0.9667\n",
      "Epoch 21/100\n",
      "742/742 - 6s - loss: 0.1541 - accuracy: 0.9640 - val_loss: 0.1361 - val_accuracy: 0.9693\n",
      "Epoch 22/100\n",
      "742/742 - 6s - loss: 0.1461 - accuracy: 0.9651 - val_loss: 0.1451 - val_accuracy: 0.9667\n",
      "Epoch 23/100\n",
      "742/742 - 6s - loss: 0.1537 - accuracy: 0.9637 - val_loss: 0.1537 - val_accuracy: 0.9663\n",
      "Epoch 24/100\n",
      "742/742 - 6s - loss: 0.1512 - accuracy: 0.9648 - val_loss: 0.1573 - val_accuracy: 0.9644\n",
      "Epoch 25/100\n",
      "742/742 - 6s - loss: 0.1517 - accuracy: 0.9646 - val_loss: 0.1441 - val_accuracy: 0.9678\n",
      "Epoch 26/100\n",
      "742/742 - 6s - loss: 0.1428 - accuracy: 0.9658 - val_loss: 0.1423 - val_accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "742/742 - 4s - loss: 0.1458 - accuracy: 0.9662 - val_loss: 0.1603 - val_accuracy: 0.9675\n",
      "Epoch 28/100\n",
      "742/742 - 6s - loss: 0.1542 - accuracy: 0.9648 - val_loss: 0.1608 - val_accuracy: 0.9672\n",
      "Epoch 29/100\n",
      "742/742 - 6s - loss: 0.1542 - accuracy: 0.9647 - val_loss: 0.1620 - val_accuracy: 0.9684\n",
      "Epoch 30/100\n",
      "742/742 - 6s - loss: 0.1555 - accuracy: 0.9656 - val_loss: 0.1467 - val_accuracy: 0.9674\n",
      "Epoch 31/100\n",
      "742/742 - 6s - loss: 0.1476 - accuracy: 0.9667 - val_loss: 0.1482 - val_accuracy: 0.9683\n",
      "Epoch 32/100\n",
      "742/742 - 5s - loss: 0.1459 - accuracy: 0.9670 - val_loss: 0.1687 - val_accuracy: 0.9657\n",
      "Epoch 33/100\n",
      "742/742 - 5s - loss: 0.1480 - accuracy: 0.9678 - val_loss: 0.1658 - val_accuracy: 0.9689\n",
      "Epoch 34/100\n",
      "742/742 - 5s - loss: 0.1511 - accuracy: 0.9657 - val_loss: 0.1538 - val_accuracy: 0.9668\n",
      "Epoch 35/100\n",
      "742/742 - 6s - loss: 0.1505 - accuracy: 0.9656 - val_loss: 0.1421 - val_accuracy: 0.9682\n",
      "Epoch 36/100\n",
      "742/742 - 6s - loss: 0.1440 - accuracy: 0.9673 - val_loss: 0.1759 - val_accuracy: 0.9669\n",
      "Epoch 37/100\n",
      "742/742 - 6s - loss: 0.1494 - accuracy: 0.9674 - val_loss: 0.1735 - val_accuracy: 0.9699\n",
      "Epoch 38/100\n",
      "742/742 - 6s - loss: 0.1511 - accuracy: 0.9661 - val_loss: 0.1723 - val_accuracy: 0.9671\n",
      "Epoch 39/100\n",
      "742/742 - 6s - loss: 0.1476 - accuracy: 0.9684 - val_loss: 0.1835 - val_accuracy: 0.9689\n",
      "Epoch 40/100\n",
      "742/742 - 6s - loss: 0.1495 - accuracy: 0.9665 - val_loss: 0.1535 - val_accuracy: 0.9683\n",
      "Epoch 41/100\n",
      "742/742 - 6s - loss: 0.1446 - accuracy: 0.9675 - val_loss: 0.1762 - val_accuracy: 0.9678\n",
      "Epoch 42/100\n",
      "742/742 - 4s - loss: 0.1513 - accuracy: 0.9681 - val_loss: 0.1921 - val_accuracy: 0.9689\n",
      "Epoch 43/100\n",
      "742/742 - 4s - loss: 0.1498 - accuracy: 0.9687 - val_loss: 0.2005 - val_accuracy: 0.9664\n",
      "Epoch 44/100\n",
      "742/742 - 5s - loss: 0.1560 - accuracy: 0.9689 - val_loss: 0.2120 - val_accuracy: 0.9675\n",
      "Epoch 45/100\n",
      "742/742 - 6s - loss: 0.1548 - accuracy: 0.9675 - val_loss: 0.1864 - val_accuracy: 0.9674\n",
      "Epoch 46/100\n",
      "742/742 - 6s - loss: 0.1626 - accuracy: 0.9657 - val_loss: 0.1892 - val_accuracy: 0.9688\n",
      "Epoch 47/100\n",
      "742/742 - 6s - loss: 0.1521 - accuracy: 0.9672 - val_loss: 0.1888 - val_accuracy: 0.9674\n",
      "Epoch 48/100\n",
      "742/742 - 6s - loss: 0.1432 - accuracy: 0.9686 - val_loss: 0.1982 - val_accuracy: 0.9702\n",
      "Epoch 49/100\n",
      "742/742 - 5s - loss: 0.1577 - accuracy: 0.9682 - val_loss: 0.1945 - val_accuracy: 0.9698\n",
      "Epoch 50/100\n",
      "742/742 - 6s - loss: 0.1705 - accuracy: 0.9664 - val_loss: 0.1638 - val_accuracy: 0.9702\n",
      "Epoch 51/100\n",
      "742/742 - 6s - loss: 0.1561 - accuracy: 0.9683 - val_loss: 0.1974 - val_accuracy: 0.9690\n",
      "Epoch 52/100\n",
      "742/742 - 6s - loss: 0.1664 - accuracy: 0.9664 - val_loss: 0.1844 - val_accuracy: 0.9678\n",
      "Epoch 53/100\n",
      "742/742 - 6s - loss: 0.1632 - accuracy: 0.9655 - val_loss: 0.2009 - val_accuracy: 0.9680\n",
      "Epoch 54/100\n",
      "742/742 - 6s - loss: 0.1741 - accuracy: 0.9659 - val_loss: 0.2066 - val_accuracy: 0.9698\n",
      "Epoch 55/100\n",
      "742/742 - 6s - loss: 0.1626 - accuracy: 0.9674 - val_loss: 0.1892 - val_accuracy: 0.9701\n",
      "Epoch 56/100\n",
      "742/742 - 6s - loss: 0.1675 - accuracy: 0.9673 - val_loss: 0.1986 - val_accuracy: 0.9675\n",
      "Epoch 57/100\n",
      "742/742 - 6s - loss: 0.1739 - accuracy: 0.9665 - val_loss: 0.2192 - val_accuracy: 0.9686\n",
      "Epoch 58/100\n",
      "742/742 - 6s - loss: 0.1710 - accuracy: 0.9665 - val_loss: 0.2218 - val_accuracy: 0.9682\n",
      "Epoch 59/100\n",
      "742/742 - 6s - loss: 0.1559 - accuracy: 0.9669 - val_loss: 0.2374 - val_accuracy: 0.9675\n",
      "Epoch 60/100\n",
      "742/742 - 6s - loss: 0.1747 - accuracy: 0.9667 - val_loss: 0.2047 - val_accuracy: 0.9694\n",
      "Epoch 61/100\n",
      "742/742 - 6s - loss: 0.1800 - accuracy: 0.9650 - val_loss: 0.2210 - val_accuracy: 0.9681\n",
      "Epoch 62/100\n",
      "742/742 - 6s - loss: 0.1685 - accuracy: 0.9649 - val_loss: 0.2434 - val_accuracy: 0.9663\n",
      "Epoch 63/100\n",
      "742/742 - 6s - loss: 0.1809 - accuracy: 0.9643 - val_loss: 0.2548 - val_accuracy: 0.9689\n",
      "Epoch 64/100\n",
      "742/742 - 6s - loss: 0.1768 - accuracy: 0.9640 - val_loss: 0.2428 - val_accuracy: 0.9664\n",
      "Epoch 65/100\n",
      "742/742 - 6s - loss: 0.1776 - accuracy: 0.9653 - val_loss: 0.2568 - val_accuracy: 0.9667\n",
      "Epoch 66/100\n",
      "742/742 - 6s - loss: 0.1879 - accuracy: 0.9640 - val_loss: 0.2206 - val_accuracy: 0.9679\n",
      "Epoch 67/100\n",
      "742/742 - 6s - loss: 0.1835 - accuracy: 0.9627 - val_loss: 0.2476 - val_accuracy: 0.9675\n",
      "Epoch 68/100\n",
      "742/742 - 5s - loss: 0.1777 - accuracy: 0.9659 - val_loss: 0.2507 - val_accuracy: 0.9675\n",
      "Epoch 69/100\n",
      "742/742 - 6s - loss: 0.1899 - accuracy: 0.9648 - val_loss: 0.2653 - val_accuracy: 0.9679\n",
      "Epoch 70/100\n",
      "742/742 - 6s - loss: 0.1843 - accuracy: 0.9637 - val_loss: 0.2356 - val_accuracy: 0.9656\n",
      "Epoch 71/100\n",
      "742/742 - 6s - loss: 0.1967 - accuracy: 0.9639 - val_loss: 0.2890 - val_accuracy: 0.9686\n",
      "Epoch 72/100\n",
      "742/742 - 5s - loss: 0.1960 - accuracy: 0.9619 - val_loss: 0.2551 - val_accuracy: 0.9681\n",
      "Epoch 73/100\n",
      "742/742 - 6s - loss: 0.1850 - accuracy: 0.9631 - val_loss: 0.2630 - val_accuracy: 0.9665\n",
      "Epoch 74/100\n",
      "742/742 - 6s - loss: 0.1935 - accuracy: 0.9633 - val_loss: 0.2698 - val_accuracy: 0.9699\n",
      "Epoch 75/100\n",
      "742/742 - 6s - loss: 0.2004 - accuracy: 0.9629 - val_loss: 0.2386 - val_accuracy: 0.9661\n",
      "Epoch 76/100\n",
      "742/742 - 5s - loss: 0.2118 - accuracy: 0.9623 - val_loss: 0.2936 - val_accuracy: 0.9658\n",
      "Epoch 77/100\n",
      "742/742 - 6s - loss: 0.1957 - accuracy: 0.9625 - val_loss: 0.2677 - val_accuracy: 0.9667\n",
      "Epoch 78/100\n",
      "742/742 - 6s - loss: 0.2165 - accuracy: 0.9616 - val_loss: 0.2378 - val_accuracy: 0.9635\n",
      "Epoch 79/100\n",
      "742/742 - 6s - loss: 0.1979 - accuracy: 0.9617 - val_loss: 0.2850 - val_accuracy: 0.9678\n",
      "Epoch 80/100\n",
      "742/742 - 6s - loss: 0.2254 - accuracy: 0.9603 - val_loss: 0.2717 - val_accuracy: 0.9658\n",
      "Epoch 81/100\n",
      "742/742 - 6s - loss: 0.2043 - accuracy: 0.9602 - val_loss: 0.3111 - val_accuracy: 0.9668\n",
      "Epoch 82/100\n",
      "742/742 - 6s - loss: 0.2187 - accuracy: 0.9581 - val_loss: 0.2695 - val_accuracy: 0.9667\n",
      "Epoch 83/100\n",
      "742/742 - 6s - loss: 0.2166 - accuracy: 0.9601 - val_loss: 0.2882 - val_accuracy: 0.9658\n",
      "Epoch 84/100\n",
      "742/742 - 6s - loss: 0.1997 - accuracy: 0.9602 - val_loss: 0.3061 - val_accuracy: 0.9655\n",
      "Epoch 85/100\n",
      "742/742 - 4s - loss: 0.2266 - accuracy: 0.9599 - val_loss: 0.2954 - val_accuracy: 0.9685\n",
      "Epoch 86/100\n",
      "742/742 - 4s - loss: 0.2157 - accuracy: 0.9597 - val_loss: 0.2643 - val_accuracy: 0.9635\n",
      "Epoch 87/100\n",
      "742/742 - 3s - loss: 0.2132 - accuracy: 0.9599 - val_loss: 0.2668 - val_accuracy: 0.9646\n",
      "Epoch 88/100\n",
      "742/742 - 6s - loss: 0.2260 - accuracy: 0.9593 - val_loss: 0.3902 - val_accuracy: 0.9620\n",
      "Epoch 89/100\n",
      "742/742 - 5s - loss: 0.2097 - accuracy: 0.9585 - val_loss: 0.4100 - val_accuracy: 0.9647\n",
      "Epoch 90/100\n",
      "742/742 - 5s - loss: 0.2238 - accuracy: 0.9588 - val_loss: 0.3639 - val_accuracy: 0.9644\n",
      "Epoch 91/100\n",
      "742/742 - 6s - loss: 0.2500 - accuracy: 0.9558 - val_loss: 0.3304 - val_accuracy: 0.9655\n",
      "Epoch 92/100\n",
      "742/742 - 6s - loss: 0.2573 - accuracy: 0.9558 - val_loss: 0.3780 - val_accuracy: 0.9607\n",
      "Epoch 93/100\n",
      "742/742 - 6s - loss: 0.2641 - accuracy: 0.9544 - val_loss: 0.3716 - val_accuracy: 0.9643\n",
      "Epoch 94/100\n",
      "742/742 - 5s - loss: 0.2436 - accuracy: 0.9568 - val_loss: 0.3398 - val_accuracy: 0.9621\n",
      "Epoch 95/100\n",
      "742/742 - 6s - loss: 0.2435 - accuracy: 0.9585 - val_loss: 0.3694 - val_accuracy: 0.9644\n",
      "Epoch 96/100\n",
      "742/742 - 6s - loss: 0.2748 - accuracy: 0.9558 - val_loss: 0.4209 - val_accuracy: 0.9617\n",
      "Epoch 97/100\n",
      "742/742 - 5s - loss: 0.2688 - accuracy: 0.9574 - val_loss: 0.3486 - val_accuracy: 0.9648\n",
      "Epoch 98/100\n",
      "742/742 - 5s - loss: 0.2764 - accuracy: 0.9546 - val_loss: 0.3036 - val_accuracy: 0.9633\n",
      "Epoch 99/100\n",
      "742/742 - 6s - loss: 0.2670 - accuracy: 0.9534 - val_loss: 0.3579 - val_accuracy: 0.9626\n",
      "Epoch 100/100\n",
      "742/742 - 5s - loss: 0.2784 - accuracy: 0.9508 - val_loss: 0.3844 - val_accuracy: 0.9638\n",
      "Accuracy: 95.77\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.1489 - accuracy: 0.9757\n",
      "Accuracy: 97.57\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4103 - accuracy: 0.9625\n",
      "Accuracy: 96.25\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()#making our initial model with no drop and regulization \n",
    "model.add(Dense(128, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.87, beta_2=0.991, epsilon=1e-07, amsgrad=False, name=\"Adam\"),metrics=['accuracy'])\n",
    "history_init = model.fit((train_x), (train_y),validation_data=((val_x),(val_y)),batch_size=68,epochs=100, verbose = 2)\n",
    "x = mean(history_init.history['accuracy'])\n",
    "print('Accuracy: %.2f' % (x*100))   \n",
    "_, accuracy = model.evaluate(x_train,y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))   \n",
    "_, accuracy = model.evaluate(x_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e49dbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "742/742 - 8s - loss: 1.4063 - accuracy: 0.4048 - val_loss: 0.8599 - val_accuracy: 0.6371\n",
      "Epoch 2/100\n",
      "742/742 - 6s - loss: 0.7066 - accuracy: 0.7592 - val_loss: 0.3125 - val_accuracy: 0.9198\n",
      "Epoch 3/100\n",
      "742/742 - 6s - loss: 0.4463 - accuracy: 0.8863 - val_loss: 0.2427 - val_accuracy: 0.9396\n",
      "Epoch 4/100\n",
      "742/742 - 7s - loss: 0.3547 - accuracy: 0.9137 - val_loss: 0.2208 - val_accuracy: 0.9464\n",
      "Epoch 5/100\n",
      "742/742 - 7s - loss: 0.3110 - accuracy: 0.9248 - val_loss: 0.2059 - val_accuracy: 0.9510\n",
      "Epoch 6/100\n",
      "742/742 - 7s - loss: 0.2919 - accuracy: 0.9302 - val_loss: 0.1989 - val_accuracy: 0.9514\n",
      "Epoch 7/100\n",
      "742/742 - 7s - loss: 0.2692 - accuracy: 0.9363 - val_loss: 0.1836 - val_accuracy: 0.9566\n",
      "Epoch 8/100\n",
      "742/742 - 7s - loss: 0.2510 - accuracy: 0.9407 - val_loss: 0.1742 - val_accuracy: 0.9603\n",
      "Epoch 9/100\n",
      "742/742 - 7s - loss: 0.2341 - accuracy: 0.9443 - val_loss: 0.1548 - val_accuracy: 0.9624\n",
      "Epoch 10/100\n",
      "742/742 - 7s - loss: 0.2296 - accuracy: 0.9465 - val_loss: 0.1720 - val_accuracy: 0.9590\n",
      "Epoch 11/100\n",
      "742/742 - 6s - loss: 0.2231 - accuracy: 0.9489 - val_loss: 0.1544 - val_accuracy: 0.9627\n",
      "Epoch 12/100\n",
      "742/742 - 7s - loss: 0.2113 - accuracy: 0.9513 - val_loss: 0.1563 - val_accuracy: 0.9626\n",
      "Epoch 13/100\n",
      "742/742 - 7s - loss: 0.2080 - accuracy: 0.9518 - val_loss: 0.1709 - val_accuracy: 0.9599\n",
      "Epoch 14/100\n",
      "742/742 - 7s - loss: 0.2047 - accuracy: 0.9533 - val_loss: 0.1610 - val_accuracy: 0.9618\n",
      "Epoch 15/100\n",
      "742/742 - 7s - loss: 0.2000 - accuracy: 0.9542 - val_loss: 0.1477 - val_accuracy: 0.9659\n",
      "Epoch 16/100\n",
      "742/742 - 7s - loss: 0.1864 - accuracy: 0.9576 - val_loss: 0.1570 - val_accuracy: 0.9646\n",
      "Epoch 17/100\n",
      "742/742 - 7s - loss: 0.1892 - accuracy: 0.9558 - val_loss: 0.1481 - val_accuracy: 0.9646\n",
      "Epoch 18/100\n",
      "742/742 - 7s - loss: 0.1910 - accuracy: 0.9565 - val_loss: 0.1587 - val_accuracy: 0.9638\n",
      "Epoch 19/100\n",
      "742/742 - 7s - loss: 0.1913 - accuracy: 0.9569 - val_loss: 0.1481 - val_accuracy: 0.9671\n",
      "Epoch 20/100\n",
      "742/742 - 7s - loss: 0.1794 - accuracy: 0.9603 - val_loss: 0.1524 - val_accuracy: 0.9668\n",
      "Epoch 21/100\n",
      "742/742 - 7s - loss: 0.1809 - accuracy: 0.9582 - val_loss: 0.1676 - val_accuracy: 0.9655\n",
      "Epoch 22/100\n",
      "742/742 - 7s - loss: 0.1793 - accuracy: 0.9607 - val_loss: 0.1626 - val_accuracy: 0.9648\n",
      "Epoch 23/100\n",
      "742/742 - 7s - loss: 0.1792 - accuracy: 0.9598 - val_loss: 0.1417 - val_accuracy: 0.9684\n",
      "Epoch 24/100\n",
      "742/742 - 7s - loss: 0.1683 - accuracy: 0.9630 - val_loss: 0.1415 - val_accuracy: 0.9685\n",
      "Epoch 25/100\n",
      "742/742 - 7s - loss: 0.1665 - accuracy: 0.9619 - val_loss: 0.1466 - val_accuracy: 0.9685\n",
      "Epoch 26/100\n",
      "742/742 - 7s - loss: 0.1711 - accuracy: 0.9622 - val_loss: 0.1416 - val_accuracy: 0.9702\n",
      "Epoch 27/100\n",
      "742/742 - 6s - loss: 0.1650 - accuracy: 0.9643 - val_loss: 0.1529 - val_accuracy: 0.9690\n",
      "Epoch 28/100\n",
      "742/742 - 7s - loss: 0.1654 - accuracy: 0.9635 - val_loss: 0.1417 - val_accuracy: 0.9706\n",
      "Epoch 29/100\n",
      "742/742 - 7s - loss: 0.1593 - accuracy: 0.9645 - val_loss: 0.1520 - val_accuracy: 0.9701\n",
      "Epoch 30/100\n",
      "742/742 - 6s - loss: 0.1629 - accuracy: 0.9643 - val_loss: 0.1407 - val_accuracy: 0.9708\n",
      "Epoch 31/100\n",
      "742/742 - 7s - loss: 0.1608 - accuracy: 0.9647 - val_loss: 0.1499 - val_accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "742/742 - 7s - loss: 0.1609 - accuracy: 0.9653 - val_loss: 0.1669 - val_accuracy: 0.9685\n",
      "Epoch 33/100\n",
      "742/742 - 7s - loss: 0.1650 - accuracy: 0.9629 - val_loss: 0.1483 - val_accuracy: 0.9696\n",
      "Epoch 34/100\n",
      "742/742 - 7s - loss: 0.1612 - accuracy: 0.9646 - val_loss: 0.1511 - val_accuracy: 0.9715\n",
      "Epoch 35/100\n",
      "742/742 - 6s - loss: 0.1608 - accuracy: 0.9655 - val_loss: 0.1421 - val_accuracy: 0.9692\n",
      "Epoch 36/100\n",
      "742/742 - 7s - loss: 0.1633 - accuracy: 0.9650 - val_loss: 0.1586 - val_accuracy: 0.9685\n",
      "Epoch 37/100\n",
      "742/742 - 6s - loss: 0.1602 - accuracy: 0.9651 - val_loss: 0.1570 - val_accuracy: 0.9685\n",
      "Epoch 38/100\n",
      "742/742 - 7s - loss: 0.1569 - accuracy: 0.9664 - val_loss: 0.1551 - val_accuracy: 0.9675\n",
      "Epoch 39/100\n",
      "742/742 - 7s - loss: 0.1558 - accuracy: 0.9674 - val_loss: 0.1595 - val_accuracy: 0.9697\n",
      "Epoch 40/100\n",
      "742/742 - 7s - loss: 0.1649 - accuracy: 0.9647 - val_loss: 0.1508 - val_accuracy: 0.9684\n",
      "Epoch 41/100\n",
      "742/742 - 6s - loss: 0.1485 - accuracy: 0.9692 - val_loss: 0.1522 - val_accuracy: 0.9691\n",
      "Epoch 42/100\n",
      "742/742 - 7s - loss: 0.1565 - accuracy: 0.9673 - val_loss: 0.1453 - val_accuracy: 0.9690\n",
      "Epoch 43/100\n",
      "742/742 - 5s - loss: 0.1547 - accuracy: 0.9669 - val_loss: 0.1574 - val_accuracy: 0.9691\n",
      "Epoch 44/100\n",
      "742/742 - 7s - loss: 0.1538 - accuracy: 0.9662 - val_loss: 0.1649 - val_accuracy: 0.9697\n",
      "Epoch 45/100\n",
      "742/742 - 7s - loss: 0.1561 - accuracy: 0.9677 - val_loss: 0.1506 - val_accuracy: 0.9699\n",
      "Epoch 46/100\n",
      "742/742 - 7s - loss: 0.1526 - accuracy: 0.9679 - val_loss: 0.1557 - val_accuracy: 0.9695\n",
      "Epoch 47/100\n",
      "742/742 - 7s - loss: 0.1439 - accuracy: 0.9689 - val_loss: 0.1644 - val_accuracy: 0.9677\n",
      "Epoch 48/100\n",
      "742/742 - 7s - loss: 0.1458 - accuracy: 0.9692 - val_loss: 0.1697 - val_accuracy: 0.9688\n",
      "Epoch 49/100\n",
      "742/742 - 7s - loss: 0.1571 - accuracy: 0.9674 - val_loss: 0.1617 - val_accuracy: 0.9681\n",
      "Epoch 50/100\n",
      "742/742 - 7s - loss: 0.1521 - accuracy: 0.9687 - val_loss: 0.1604 - val_accuracy: 0.9695\n",
      "Epoch 51/100\n",
      "742/742 - 6s - loss: 0.1512 - accuracy: 0.9684 - val_loss: 0.1698 - val_accuracy: 0.9693\n",
      "Epoch 52/100\n",
      "742/742 - 7s - loss: 0.1454 - accuracy: 0.9701 - val_loss: 0.1712 - val_accuracy: 0.9681\n",
      "Epoch 53/100\n",
      "742/742 - 6s - loss: 0.1400 - accuracy: 0.9708 - val_loss: 0.1679 - val_accuracy: 0.9696\n",
      "Epoch 54/100\n",
      "742/742 - 7s - loss: 0.1586 - accuracy: 0.9679 - val_loss: 0.1621 - val_accuracy: 0.9694\n",
      "Epoch 55/100\n",
      "742/742 - 7s - loss: 0.1427 - accuracy: 0.9706 - val_loss: 0.1597 - val_accuracy: 0.9706\n",
      "Epoch 56/100\n",
      "742/742 - 7s - loss: 0.1439 - accuracy: 0.9696 - val_loss: 0.1592 - val_accuracy: 0.9708\n",
      "Epoch 57/100\n",
      "742/742 - 7s - loss: 0.1459 - accuracy: 0.9703 - val_loss: 0.1675 - val_accuracy: 0.9689\n",
      "Epoch 58/100\n",
      "742/742 - 6s - loss: 0.1517 - accuracy: 0.9688 - val_loss: 0.1623 - val_accuracy: 0.9703\n",
      "Epoch 59/100\n",
      "742/742 - 7s - loss: 0.1476 - accuracy: 0.9704 - val_loss: 0.1585 - val_accuracy: 0.9714\n",
      "Epoch 60/100\n",
      "742/742 - 6s - loss: 0.1480 - accuracy: 0.9699 - val_loss: 0.1603 - val_accuracy: 0.9715\n",
      "Epoch 61/100\n",
      "742/742 - 7s - loss: 0.1517 - accuracy: 0.9688 - val_loss: 0.1602 - val_accuracy: 0.9692\n",
      "Epoch 62/100\n",
      "742/742 - 7s - loss: 0.1413 - accuracy: 0.9712 - val_loss: 0.1704 - val_accuracy: 0.9698\n",
      "Epoch 63/100\n",
      "742/742 - 7s - loss: 0.1375 - accuracy: 0.9721 - val_loss: 0.1692 - val_accuracy: 0.9714\n",
      "Epoch 64/100\n",
      "742/742 - 7s - loss: 0.1432 - accuracy: 0.9701 - val_loss: 0.1569 - val_accuracy: 0.9697\n",
      "Epoch 65/100\n",
      "742/742 - 7s - loss: 0.1468 - accuracy: 0.9690 - val_loss: 0.1574 - val_accuracy: 0.9708\n",
      "Epoch 66/100\n",
      "742/742 - 7s - loss: 0.1456 - accuracy: 0.9703 - val_loss: 0.1568 - val_accuracy: 0.9712\n",
      "Epoch 67/100\n",
      "742/742 - 7s - loss: 0.1481 - accuracy: 0.9695 - val_loss: 0.1674 - val_accuracy: 0.9694\n",
      "Epoch 68/100\n",
      "742/742 - 7s - loss: 0.1431 - accuracy: 0.9704 - val_loss: 0.1713 - val_accuracy: 0.9673\n",
      "Epoch 69/100\n",
      "742/742 - 7s - loss: 0.1427 - accuracy: 0.9703 - val_loss: 0.1605 - val_accuracy: 0.9711\n",
      "Epoch 70/100\n",
      "742/742 - 7s - loss: 0.1531 - accuracy: 0.9686 - val_loss: 0.1612 - val_accuracy: 0.9688\n",
      "Epoch 71/100\n",
      "742/742 - 7s - loss: 0.1492 - accuracy: 0.9694 - val_loss: 0.1645 - val_accuracy: 0.9685\n",
      "Epoch 72/100\n",
      "742/742 - 7s - loss: 0.1442 - accuracy: 0.9699 - val_loss: 0.1653 - val_accuracy: 0.9719\n",
      "Epoch 73/100\n",
      "742/742 - 6s - loss: 0.1494 - accuracy: 0.9694 - val_loss: 0.1639 - val_accuracy: 0.9697\n",
      "Epoch 74/100\n",
      "742/742 - 6s - loss: 0.1544 - accuracy: 0.9689 - val_loss: 0.1588 - val_accuracy: 0.9697\n",
      "Epoch 75/100\n",
      "742/742 - 6s - loss: 0.1450 - accuracy: 0.9706 - val_loss: 0.1714 - val_accuracy: 0.9690\n",
      "Epoch 76/100\n",
      "742/742 - 7s - loss: 0.1411 - accuracy: 0.9700 - val_loss: 0.1662 - val_accuracy: 0.9679\n",
      "Epoch 77/100\n",
      "742/742 - 7s - loss: 0.1464 - accuracy: 0.9697 - val_loss: 0.1655 - val_accuracy: 0.9696\n",
      "Epoch 78/100\n",
      "742/742 - 6s - loss: 0.1430 - accuracy: 0.9702 - val_loss: 0.1627 - val_accuracy: 0.9708\n",
      "Epoch 79/100\n",
      "742/742 - 7s - loss: 0.1438 - accuracy: 0.9711 - val_loss: 0.1695 - val_accuracy: 0.9724\n",
      "Epoch 80/100\n",
      "742/742 - 6s - loss: 0.1568 - accuracy: 0.9691 - val_loss: 0.1774 - val_accuracy: 0.9706\n",
      "Epoch 81/100\n",
      "742/742 - 7s - loss: 0.1504 - accuracy: 0.9691 - val_loss: 0.1660 - val_accuracy: 0.9697\n",
      "Epoch 82/100\n",
      "742/742 - 7s - loss: 0.1459 - accuracy: 0.9702 - val_loss: 0.1553 - val_accuracy: 0.9706\n",
      "Epoch 83/100\n",
      "742/742 - 7s - loss: 0.1429 - accuracy: 0.9705 - val_loss: 0.1623 - val_accuracy: 0.9714\n",
      "Epoch 84/100\n",
      "742/742 - 7s - loss: 0.1477 - accuracy: 0.9697 - val_loss: 0.1718 - val_accuracy: 0.9689\n",
      "Epoch 85/100\n",
      "742/742 - 6s - loss: 0.1539 - accuracy: 0.9691 - val_loss: 0.1626 - val_accuracy: 0.9685\n",
      "Epoch 86/100\n",
      "742/742 - 6s - loss: 0.1438 - accuracy: 0.9717 - val_loss: 0.1637 - val_accuracy: 0.9722\n",
      "Epoch 87/100\n",
      "742/742 - 7s - loss: 0.1437 - accuracy: 0.9704 - val_loss: 0.1630 - val_accuracy: 0.9705\n",
      "Epoch 88/100\n",
      "742/742 - 7s - loss: 0.1399 - accuracy: 0.9712 - val_loss: 0.1656 - val_accuracy: 0.9710\n",
      "Epoch 89/100\n",
      "742/742 - 7s - loss: 0.1466 - accuracy: 0.9702 - val_loss: 0.1641 - val_accuracy: 0.9704\n",
      "Epoch 90/100\n",
      "742/742 - 7s - loss: 0.1482 - accuracy: 0.9703 - val_loss: 0.1815 - val_accuracy: 0.9692\n",
      "Epoch 91/100\n",
      "742/742 - 7s - loss: 0.1472 - accuracy: 0.9694 - val_loss: 0.1563 - val_accuracy: 0.9722\n",
      "Epoch 92/100\n",
      "742/742 - 7s - loss: 0.1347 - accuracy: 0.9724 - val_loss: 0.1818 - val_accuracy: 0.9701\n",
      "Epoch 93/100\n",
      "742/742 - 6s - loss: 0.1430 - accuracy: 0.9707 - val_loss: 0.1691 - val_accuracy: 0.9696\n",
      "Epoch 94/100\n",
      "742/742 - 7s - loss: 0.1393 - accuracy: 0.9711 - val_loss: 0.1796 - val_accuracy: 0.9700\n",
      "Epoch 95/100\n",
      "742/742 - 6s - loss: 0.1483 - accuracy: 0.9691 - val_loss: 0.1554 - val_accuracy: 0.9704\n",
      "Epoch 96/100\n",
      "742/742 - 7s - loss: 0.1375 - accuracy: 0.9712 - val_loss: 0.1685 - val_accuracy: 0.9723\n",
      "Epoch 97/100\n",
      "742/742 - 6s - loss: 0.1367 - accuracy: 0.9728 - val_loss: 0.1617 - val_accuracy: 0.9696\n",
      "Epoch 98/100\n",
      "742/742 - 7s - loss: 0.1561 - accuracy: 0.9683 - val_loss: 0.1693 - val_accuracy: 0.9699\n",
      "Epoch 99/100\n",
      "742/742 - 7s - loss: 0.1377 - accuracy: 0.9724 - val_loss: 0.1693 - val_accuracy: 0.9697\n",
      "Epoch 100/100\n",
      "742/742 - 7s - loss: 0.1511 - accuracy: 0.9700 - val_loss: 0.1591 - val_accuracy: 0.9700\n",
      "Accuracy: 95.59\n",
      "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0777 - accuracy: 0.9835\n",
      "Accuracy: 98.35\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1468 - accuracy: 0.9720\n",
      "Accuracy: 97.20\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(128, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(32, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.87, beta_2=0.991, epsilon=1e-07, amsgrad=False, name=\"Adam\"),metrics=['accuracy'])\n",
    "history_init = model.fit((train_x), (train_y),validation_data=((val_x),(val_y)),batch_size=68,epochs=100, verbose = 2)\n",
    "x = mean(history_init.history['accuracy'])\n",
    "print('Accuracy: %.2f' % (x*100))   \n",
    "_, accuracy = model.evaluate(x_train,y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))   \n",
    "_, accuracy = model.evaluate(x_test,y_test).\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0146ea2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "742/742 - 8s - loss: 1.5248 - accuracy: 0.3830 - val_loss: 0.8742 - val_accuracy: 0.6040\n",
      "Epoch 2/100\n",
      "742/742 - 7s - loss: 0.7830 - accuracy: 0.7318 - val_loss: 0.3184 - val_accuracy: 0.9191\n",
      "Epoch 3/100\n",
      "742/742 - 7s - loss: 0.4722 - accuracy: 0.8783 - val_loss: 0.2660 - val_accuracy: 0.9319\n",
      "Epoch 4/100\n",
      "742/742 - 8s - loss: 0.3565 - accuracy: 0.9129 - val_loss: 0.2196 - val_accuracy: 0.9481\n",
      "Epoch 5/100\n",
      "742/742 - 8s - loss: 0.3088 - accuracy: 0.9277 - val_loss: 0.2022 - val_accuracy: 0.9466\n",
      "Epoch 6/100\n",
      "742/742 - 7s - loss: 0.2880 - accuracy: 0.9318 - val_loss: 0.2127 - val_accuracy: 0.9507\n",
      "Epoch 7/100\n",
      "742/742 - 7s - loss: 0.2683 - accuracy: 0.9363 - val_loss: 0.1774 - val_accuracy: 0.9580\n",
      "Epoch 8/100\n",
      "742/742 - 7s - loss: 0.2456 - accuracy: 0.9423 - val_loss: 0.1680 - val_accuracy: 0.9575\n",
      "Epoch 9/100\n",
      "742/742 - 7s - loss: 0.2345 - accuracy: 0.9459 - val_loss: 0.1723 - val_accuracy: 0.9597\n",
      "Epoch 10/100\n",
      "742/742 - 7s - loss: 0.2240 - accuracy: 0.9475 - val_loss: 0.1825 - val_accuracy: 0.9596\n",
      "Epoch 11/100\n",
      "742/742 - 7s - loss: 0.2177 - accuracy: 0.9503 - val_loss: 0.1678 - val_accuracy: 0.9617\n",
      "Epoch 12/100\n",
      "742/742 - 8s - loss: 0.2121 - accuracy: 0.9509 - val_loss: 0.1672 - val_accuracy: 0.9607\n",
      "Epoch 13/100\n",
      "742/742 - 8s - loss: 0.1995 - accuracy: 0.9536 - val_loss: 0.1546 - val_accuracy: 0.9651\n",
      "Epoch 14/100\n",
      "742/742 - 8s - loss: 0.1970 - accuracy: 0.9547 - val_loss: 0.1508 - val_accuracy: 0.9638\n",
      "Epoch 15/100\n",
      "742/742 - 8s - loss: 0.1925 - accuracy: 0.9559 - val_loss: 0.1368 - val_accuracy: 0.9668\n",
      "Epoch 16/100\n",
      "742/742 - 8s - loss: 0.1873 - accuracy: 0.9581 - val_loss: 0.1512 - val_accuracy: 0.9649\n",
      "Epoch 17/100\n",
      "742/742 - 7s - loss: 0.1868 - accuracy: 0.9579 - val_loss: 0.1565 - val_accuracy: 0.9655\n",
      "Epoch 18/100\n",
      "742/742 - 7s - loss: 0.1889 - accuracy: 0.9580 - val_loss: 0.1453 - val_accuracy: 0.9663\n",
      "Epoch 19/100\n",
      "742/742 - 7s - loss: 0.1811 - accuracy: 0.9593 - val_loss: 0.1351 - val_accuracy: 0.9679\n",
      "Epoch 20/100\n",
      "742/742 - 7s - loss: 0.1859 - accuracy: 0.9594 - val_loss: 0.1357 - val_accuracy: 0.9685\n",
      "Epoch 21/100\n",
      "742/742 - 7s - loss: 0.1799 - accuracy: 0.9612 - val_loss: 0.1625 - val_accuracy: 0.9661\n",
      "Epoch 22/100\n",
      "742/742 - 7s - loss: 0.1778 - accuracy: 0.9602 - val_loss: 0.1538 - val_accuracy: 0.9663\n",
      "Epoch 23/100\n",
      "742/742 - 7s - loss: 0.1728 - accuracy: 0.9625 - val_loss: 0.1477 - val_accuracy: 0.9652\n",
      "Epoch 24/100\n",
      "742/742 - 6s - loss: 0.1755 - accuracy: 0.9615 - val_loss: 0.1536 - val_accuracy: 0.9678\n",
      "Epoch 25/100\n",
      "742/742 - 4s - loss: 0.1698 - accuracy: 0.9619 - val_loss: 0.1570 - val_accuracy: 0.9665\n",
      "Epoch 26/100\n",
      "742/742 - 5s - loss: 0.1700 - accuracy: 0.9621 - val_loss: 0.1513 - val_accuracy: 0.9676\n",
      "Epoch 27/100\n",
      "742/742 - 6s - loss: 0.1727 - accuracy: 0.9630 - val_loss: 0.1535 - val_accuracy: 0.9673\n",
      "Epoch 28/100\n",
      "742/742 - 5s - loss: 0.1677 - accuracy: 0.9634 - val_loss: 0.1523 - val_accuracy: 0.9702\n",
      "Epoch 29/100\n",
      "742/742 - 6s - loss: 0.1697 - accuracy: 0.9631 - val_loss: 0.1623 - val_accuracy: 0.9663\n",
      "Epoch 30/100\n",
      "742/742 - 4s - loss: 0.1724 - accuracy: 0.9638 - val_loss: 0.1634 - val_accuracy: 0.9654\n",
      "Epoch 31/100\n",
      "742/742 - 5s - loss: 0.1602 - accuracy: 0.9659 - val_loss: 0.1596 - val_accuracy: 0.9704\n",
      "Epoch 32/100\n",
      "742/742 - 6s - loss: 0.1572 - accuracy: 0.9672 - val_loss: 0.1587 - val_accuracy: 0.9670\n",
      "Epoch 33/100\n",
      "742/742 - 5s - loss: 0.1551 - accuracy: 0.9667 - val_loss: 0.1510 - val_accuracy: 0.9690\n",
      "Epoch 34/100\n",
      "742/742 - 6s - loss: 0.1552 - accuracy: 0.9663 - val_loss: 0.1511 - val_accuracy: 0.9704\n",
      "Epoch 35/100\n",
      "742/742 - 5s - loss: 0.1615 - accuracy: 0.9655 - val_loss: 0.1540 - val_accuracy: 0.9688\n",
      "Epoch 36/100\n",
      "742/742 - 8s - loss: 0.1611 - accuracy: 0.9667 - val_loss: 0.1555 - val_accuracy: 0.9693\n",
      "Epoch 37/100\n",
      "742/742 - 8s - loss: 0.1639 - accuracy: 0.9653 - val_loss: 0.1634 - val_accuracy: 0.9678\n",
      "Epoch 38/100\n",
      "742/742 - 8s - loss: 0.1680 - accuracy: 0.9656 - val_loss: 0.1599 - val_accuracy: 0.9672\n",
      "Epoch 39/100\n",
      "742/742 - 7s - loss: 0.1591 - accuracy: 0.9667 - val_loss: 0.1392 - val_accuracy: 0.9700\n",
      "Epoch 40/100\n",
      "742/742 - 7s - loss: 0.1623 - accuracy: 0.9665 - val_loss: 0.1491 - val_accuracy: 0.9709\n",
      "Epoch 41/100\n",
      "742/742 - 8s - loss: 0.1588 - accuracy: 0.9669 - val_loss: 0.1514 - val_accuracy: 0.9691\n",
      "Epoch 42/100\n",
      "742/742 - 5s - loss: 0.1567 - accuracy: 0.9679 - val_loss: 0.1529 - val_accuracy: 0.9683\n",
      "Epoch 43/100\n",
      "742/742 - 4s - loss: 0.1552 - accuracy: 0.9678 - val_loss: 0.1635 - val_accuracy: 0.9696\n",
      "Epoch 44/100\n",
      "742/742 - 7s - loss: 0.1584 - accuracy: 0.9677 - val_loss: 0.1517 - val_accuracy: 0.9723\n",
      "Epoch 45/100\n",
      "742/742 - 5s - loss: 0.1608 - accuracy: 0.9674 - val_loss: 0.1500 - val_accuracy: 0.9706\n",
      "Epoch 46/100\n",
      "742/742 - 7s - loss: 0.1582 - accuracy: 0.9678 - val_loss: 0.1681 - val_accuracy: 0.9683\n",
      "Epoch 47/100\n",
      "742/742 - 7s - loss: 0.1612 - accuracy: 0.9671 - val_loss: 0.1738 - val_accuracy: 0.9691\n",
      "Epoch 48/100\n",
      "742/742 - 8s - loss: 0.1565 - accuracy: 0.9682 - val_loss: 0.1532 - val_accuracy: 0.9707\n",
      "Epoch 49/100\n",
      "742/742 - 7s - loss: 0.1580 - accuracy: 0.9687 - val_loss: 0.1538 - val_accuracy: 0.9683\n",
      "Epoch 50/100\n",
      "742/742 - 7s - loss: 0.1583 - accuracy: 0.9676 - val_loss: 0.1626 - val_accuracy: 0.9693\n",
      "Epoch 51/100\n",
      "742/742 - 6s - loss: 0.1538 - accuracy: 0.9687 - val_loss: 0.1576 - val_accuracy: 0.9698\n",
      "Epoch 52/100\n",
      "742/742 - 6s - loss: 0.1589 - accuracy: 0.9683 - val_loss: 0.1517 - val_accuracy: 0.9704\n",
      "Epoch 53/100\n",
      "742/742 - 7s - loss: 0.1547 - accuracy: 0.9676 - val_loss: 0.1506 - val_accuracy: 0.9704\n",
      "Epoch 54/100\n",
      "742/742 - 7s - loss: 0.1599 - accuracy: 0.9670 - val_loss: 0.1441 - val_accuracy: 0.9688\n",
      "Epoch 55/100\n",
      "742/742 - 7s - loss: 0.1649 - accuracy: 0.9662 - val_loss: 0.1437 - val_accuracy: 0.9721\n",
      "Epoch 56/100\n",
      "742/742 - 6s - loss: 0.1671 - accuracy: 0.9667 - val_loss: 0.1550 - val_accuracy: 0.9707\n",
      "Epoch 57/100\n",
      "742/742 - 7s - loss: 0.1472 - accuracy: 0.9704 - val_loss: 0.1588 - val_accuracy: 0.9723\n",
      "Epoch 58/100\n",
      "742/742 - 6s - loss: 0.1541 - accuracy: 0.9685 - val_loss: 0.1582 - val_accuracy: 0.9724\n",
      "Epoch 59/100\n",
      "742/742 - 7s - loss: 0.1469 - accuracy: 0.9705 - val_loss: 0.1589 - val_accuracy: 0.9721\n",
      "Epoch 60/100\n",
      "742/742 - 7s - loss: 0.1609 - accuracy: 0.9678 - val_loss: 0.1480 - val_accuracy: 0.9714\n",
      "Epoch 61/100\n",
      "742/742 - 7s - loss: 0.1613 - accuracy: 0.9681 - val_loss: 0.1606 - val_accuracy: 0.9701\n",
      "Epoch 62/100\n",
      "742/742 - 7s - loss: 0.1526 - accuracy: 0.9691 - val_loss: 0.1605 - val_accuracy: 0.9690\n",
      "Epoch 63/100\n",
      "742/742 - 7s - loss: 0.1539 - accuracy: 0.9695 - val_loss: 0.1573 - val_accuracy: 0.9692\n",
      "Epoch 64/100\n",
      "742/742 - 8s - loss: 0.1603 - accuracy: 0.9677 - val_loss: 0.1660 - val_accuracy: 0.9692\n",
      "Epoch 65/100\n",
      "742/742 - 7s - loss: 0.1631 - accuracy: 0.9682 - val_loss: 0.1605 - val_accuracy: 0.9703\n",
      "Epoch 66/100\n",
      "742/742 - 7s - loss: 0.1543 - accuracy: 0.9700 - val_loss: 0.1453 - val_accuracy: 0.9720\n",
      "Epoch 67/100\n",
      "742/742 - 8s - loss: 0.1494 - accuracy: 0.9700 - val_loss: 0.1541 - val_accuracy: 0.9704\n",
      "Epoch 68/100\n",
      "742/742 - 6s - loss: 0.1569 - accuracy: 0.9692 - val_loss: 0.1586 - val_accuracy: 0.9696\n",
      "Epoch 69/100\n",
      "742/742 - 6s - loss: 0.1551 - accuracy: 0.9692 - val_loss: 0.1474 - val_accuracy: 0.9702\n",
      "Epoch 70/100\n",
      "742/742 - 7s - loss: 0.1498 - accuracy: 0.9698 - val_loss: 0.1527 - val_accuracy: 0.9703\n",
      "Epoch 71/100\n",
      "742/742 - 5s - loss: 0.1545 - accuracy: 0.9693 - val_loss: 0.1481 - val_accuracy: 0.9708\n",
      "Epoch 72/100\n",
      "742/742 - 5s - loss: 0.1585 - accuracy: 0.9685 - val_loss: 0.1586 - val_accuracy: 0.9714\n",
      "Epoch 73/100\n",
      "742/742 - 7s - loss: 0.1583 - accuracy: 0.9691 - val_loss: 0.1580 - val_accuracy: 0.9691\n",
      "Epoch 74/100\n",
      "742/742 - 7s - loss: 0.1494 - accuracy: 0.9713 - val_loss: 0.1709 - val_accuracy: 0.9692\n",
      "Epoch 75/100\n",
      "742/742 - 7s - loss: 0.1574 - accuracy: 0.9689 - val_loss: 0.1524 - val_accuracy: 0.9728\n",
      "Epoch 76/100\n",
      "742/742 - 7s - loss: 0.1499 - accuracy: 0.9702 - val_loss: 0.1622 - val_accuracy: 0.9700\n",
      "Epoch 77/100\n",
      "742/742 - 7s - loss: 0.1597 - accuracy: 0.9689 - val_loss: 0.1609 - val_accuracy: 0.9701\n",
      "Epoch 78/100\n",
      "742/742 - 7s - loss: 0.1557 - accuracy: 0.9695 - val_loss: 0.1648 - val_accuracy: 0.9719\n",
      "Epoch 79/100\n",
      "742/742 - 8s - loss: 0.1526 - accuracy: 0.9695 - val_loss: 0.1601 - val_accuracy: 0.9694\n",
      "Epoch 80/100\n",
      "742/742 - 7s - loss: 0.1555 - accuracy: 0.9683 - val_loss: 0.1653 - val_accuracy: 0.9690\n",
      "Epoch 81/100\n",
      "742/742 - 7s - loss: 0.1575 - accuracy: 0.9684 - val_loss: 0.1449 - val_accuracy: 0.9710\n",
      "Epoch 82/100\n",
      "742/742 - 8s - loss: 0.1532 - accuracy: 0.9709 - val_loss: 0.1610 - val_accuracy: 0.9668\n",
      "Epoch 83/100\n",
      "742/742 - 7s - loss: 0.1551 - accuracy: 0.9691 - val_loss: 0.1691 - val_accuracy: 0.9685\n",
      "Epoch 84/100\n",
      "742/742 - 10s - loss: 0.1603 - accuracy: 0.9687 - val_loss: 0.1675 - val_accuracy: 0.9694\n",
      "Epoch 85/100\n",
      "742/742 - 3s - loss: 0.1475 - accuracy: 0.9713 - val_loss: 0.1486 - val_accuracy: 0.9734\n",
      "Epoch 86/100\n",
      "742/742 - 3s - loss: 0.1590 - accuracy: 0.9683 - val_loss: 0.1570 - val_accuracy: 0.9705\n",
      "Epoch 87/100\n",
      "742/742 - 3s - loss: 0.1639 - accuracy: 0.9683 - val_loss: 0.1702 - val_accuracy: 0.9694\n",
      "Epoch 88/100\n",
      "742/742 - 3s - loss: 0.1613 - accuracy: 0.9676 - val_loss: 0.1590 - val_accuracy: 0.9707\n",
      "Epoch 89/100\n",
      "742/742 - 3s - loss: 0.1580 - accuracy: 0.9677 - val_loss: 0.1530 - val_accuracy: 0.9707\n",
      "Epoch 90/100\n",
      "742/742 - 3s - loss: 0.1544 - accuracy: 0.9696 - val_loss: 0.1658 - val_accuracy: 0.9716\n",
      "Epoch 91/100\n",
      "742/742 - 3s - loss: 0.1500 - accuracy: 0.9696 - val_loss: 0.1713 - val_accuracy: 0.9695\n",
      "Epoch 92/100\n",
      "742/742 - 3s - loss: 0.1568 - accuracy: 0.9696 - val_loss: 0.1661 - val_accuracy: 0.9703\n",
      "Epoch 93/100\n",
      "742/742 - 3s - loss: 0.1584 - accuracy: 0.9686 - val_loss: 0.1664 - val_accuracy: 0.9700\n",
      "Epoch 94/100\n",
      "742/742 - 2s - loss: 0.1562 - accuracy: 0.9691 - val_loss: 0.1532 - val_accuracy: 0.9729\n",
      "Epoch 95/100\n",
      "742/742 - 3s - loss: 0.1507 - accuracy: 0.9706 - val_loss: 0.1603 - val_accuracy: 0.9714\n",
      "Epoch 96/100\n",
      "742/742 - 3s - loss: 0.1516 - accuracy: 0.9696 - val_loss: 0.1651 - val_accuracy: 0.9705\n",
      "Epoch 97/100\n",
      "742/742 - 3s - loss: 0.1551 - accuracy: 0.9700 - val_loss: 0.1694 - val_accuracy: 0.9714\n",
      "Epoch 98/100\n",
      "742/742 - 3s - loss: 0.1605 - accuracy: 0.9694 - val_loss: 0.1495 - val_accuracy: 0.9725\n",
      "Epoch 99/100\n",
      "742/742 - 3s - loss: 0.1652 - accuracy: 0.9676 - val_loss: 0.1482 - val_accuracy: 0.9735\n",
      "Epoch 100/100\n",
      "742/742 - 3s - loss: 0.1480 - accuracy: 0.9704 - val_loss: 0.1524 - val_accuracy: 0.9728\n",
      "Accuracy: 95.51\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0894 - accuracy: 0.9828: 0s - loss: 0.092\n",
      "Accuracy: 98.28\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1582 - accuracy: 0.9716\n",
      "Accuracy: 97.16\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(128, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(32, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.87, beta_2=0.991, epsilon=1e-07, amsgrad=False, name=\"Adam\"),metrics=['accuracy'])\n",
    "history_init = model.fit((train_x), (train_y),validation_data=((val_x),(val_y)),batch_size=68,epochs=100, verbose = 2)\n",
    "x = mean(history_init.history['accuracy'])\n",
    "print('Accuracy: %.2f' % (x*100))   \n",
    "_, accuracy = model.evaluate(x_train,y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))   \n",
    "_, accuracy = model.evaluate(x_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da8f04f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "742/742 - 4s - loss: 0.9389 - accuracy: 0.6651 - val_loss: 0.2649 - val_accuracy: 0.9362\n",
      "Epoch 2/100\n",
      "742/742 - 2s - loss: 0.3956 - accuracy: 0.8924 - val_loss: 0.1907 - val_accuracy: 0.9502\n",
      "Epoch 3/100\n",
      "742/742 - 2s - loss: 0.2807 - accuracy: 0.9261 - val_loss: 0.1642 - val_accuracy: 0.9570\n",
      "Epoch 4/100\n",
      "742/742 - 2s - loss: 0.2340 - accuracy: 0.9392 - val_loss: 0.1543 - val_accuracy: 0.9586\n",
      "Epoch 5/100\n",
      "742/742 - 2s - loss: 0.2095 - accuracy: 0.9453 - val_loss: 0.1470 - val_accuracy: 0.9583\n",
      "Epoch 6/100\n",
      "742/742 - 2s - loss: 0.2007 - accuracy: 0.9479 - val_loss: 0.1538 - val_accuracy: 0.9593\n",
      "Epoch 7/100\n",
      "742/742 - 2s - loss: 0.1902 - accuracy: 0.9518 - val_loss: 0.1451 - val_accuracy: 0.9636\n",
      "Epoch 8/100\n",
      "742/742 - 2s - loss: 0.1840 - accuracy: 0.9520 - val_loss: 0.1455 - val_accuracy: 0.9635\n",
      "Epoch 9/100\n",
      "742/742 - 2s - loss: 0.1839 - accuracy: 0.9532 - val_loss: 0.1389 - val_accuracy: 0.9641\n",
      "Epoch 10/100\n",
      "742/742 - 2s - loss: 0.1833 - accuracy: 0.9534 - val_loss: 0.1308 - val_accuracy: 0.9649\n",
      "Epoch 11/100\n",
      "742/742 - 2s - loss: 0.1751 - accuracy: 0.9563 - val_loss: 0.1292 - val_accuracy: 0.9671\n",
      "Epoch 12/100\n",
      "742/742 - 2s - loss: 0.1675 - accuracy: 0.9589 - val_loss: 0.1555 - val_accuracy: 0.9629\n",
      "Epoch 13/100\n",
      "742/742 - 2s - loss: 0.1714 - accuracy: 0.9589 - val_loss: 0.1363 - val_accuracy: 0.9675\n",
      "Epoch 14/100\n",
      "742/742 - 2s - loss: 0.1678 - accuracy: 0.9589 - val_loss: 0.1316 - val_accuracy: 0.9655\n",
      "Epoch 15/100\n",
      "742/742 - 2s - loss: 0.1661 - accuracy: 0.9603 - val_loss: 0.1405 - val_accuracy: 0.9661\n",
      "Epoch 16/100\n",
      "742/742 - 2s - loss: 0.1588 - accuracy: 0.9607 - val_loss: 0.1393 - val_accuracy: 0.9664\n",
      "Epoch 17/100\n",
      "742/742 - 2s - loss: 0.1618 - accuracy: 0.9614 - val_loss: 0.1340 - val_accuracy: 0.9658\n",
      "Epoch 18/100\n",
      "742/742 - 2s - loss: 0.1605 - accuracy: 0.9614 - val_loss: 0.1415 - val_accuracy: 0.9666\n",
      "Epoch 19/100\n",
      "742/742 - 2s - loss: 0.1671 - accuracy: 0.9597 - val_loss: 0.1289 - val_accuracy: 0.9694\n",
      "Epoch 20/100\n",
      "742/742 - 2s - loss: 0.1623 - accuracy: 0.9625 - val_loss: 0.1527 - val_accuracy: 0.9661\n",
      "Epoch 21/100\n",
      "742/742 - 2s - loss: 0.1627 - accuracy: 0.9619 - val_loss: 0.1445 - val_accuracy: 0.9667\n",
      "Epoch 22/100\n",
      "742/742 - 2s - loss: 0.1615 - accuracy: 0.9637 - val_loss: 0.1443 - val_accuracy: 0.9640\n",
      "Epoch 23/100\n",
      "742/742 - 2s - loss: 0.1579 - accuracy: 0.9642 - val_loss: 0.1632 - val_accuracy: 0.9686\n",
      "Epoch 24/100\n",
      "742/742 - 2s - loss: 0.1621 - accuracy: 0.9641 - val_loss: 0.1427 - val_accuracy: 0.9677\n",
      "Epoch 25/100\n",
      "742/742 - 2s - loss: 0.1557 - accuracy: 0.9652 - val_loss: 0.1538 - val_accuracy: 0.9682\n",
      "Epoch 26/100\n",
      "742/742 - 2s - loss: 0.1590 - accuracy: 0.9638 - val_loss: 0.1552 - val_accuracy: 0.9671\n",
      "Epoch 27/100\n",
      "742/742 - 3s - loss: 0.1567 - accuracy: 0.9641 - val_loss: 0.1517 - val_accuracy: 0.9671\n",
      "Epoch 28/100\n",
      "742/742 - 3s - loss: 0.1602 - accuracy: 0.9658 - val_loss: 0.1462 - val_accuracy: 0.9674\n",
      "Epoch 29/100\n",
      "742/742 - 2s - loss: 0.1633 - accuracy: 0.9645 - val_loss: 0.1582 - val_accuracy: 0.9680\n",
      "Epoch 30/100\n",
      "742/742 - 2s - loss: 0.1597 - accuracy: 0.9659 - val_loss: 0.1560 - val_accuracy: 0.9674\n",
      "Epoch 31/100\n",
      "742/742 - 2s - loss: 0.1579 - accuracy: 0.9661 - val_loss: 0.1558 - val_accuracy: 0.9685\n",
      "Epoch 32/100\n",
      "742/742 - 2s - loss: 0.1745 - accuracy: 0.9637 - val_loss: 0.1529 - val_accuracy: 0.9658\n",
      "Epoch 33/100\n",
      "742/742 - 2s - loss: 0.1689 - accuracy: 0.9636 - val_loss: 0.1583 - val_accuracy: 0.9663\n",
      "Epoch 34/100\n",
      "742/742 - 2s - loss: 0.1628 - accuracy: 0.9653 - val_loss: 0.1622 - val_accuracy: 0.9691\n",
      "Epoch 35/100\n",
      "742/742 - 2s - loss: 0.1721 - accuracy: 0.9630 - val_loss: 0.1739 - val_accuracy: 0.9672\n",
      "Epoch 36/100\n",
      "742/742 - 2s - loss: 0.1589 - accuracy: 0.9662 - val_loss: 0.1630 - val_accuracy: 0.9676\n",
      "Epoch 37/100\n",
      "742/742 - 2s - loss: 0.1611 - accuracy: 0.9654 - val_loss: 0.1538 - val_accuracy: 0.9686\n",
      "Epoch 38/100\n",
      "742/742 - 2s - loss: 0.1671 - accuracy: 0.9651 - val_loss: 0.1640 - val_accuracy: 0.9675\n",
      "Epoch 39/100\n",
      "742/742 - 2s - loss: 0.1508 - accuracy: 0.9680 - val_loss: 0.1472 - val_accuracy: 0.9695\n",
      "Epoch 40/100\n",
      "742/742 - 2s - loss: 0.1627 - accuracy: 0.9663 - val_loss: 0.1622 - val_accuracy: 0.9668\n",
      "Epoch 41/100\n",
      "742/742 - 2s - loss: 0.1539 - accuracy: 0.9675 - val_loss: 0.1613 - val_accuracy: 0.9692\n",
      "Epoch 42/100\n",
      "742/742 - 2s - loss: 0.1546 - accuracy: 0.9684 - val_loss: 0.1529 - val_accuracy: 0.9703\n",
      "Epoch 43/100\n",
      "742/742 - 2s - loss: 0.1580 - accuracy: 0.9676 - val_loss: 0.1772 - val_accuracy: 0.9695\n",
      "Epoch 44/100\n",
      "742/742 - 2s - loss: 0.1639 - accuracy: 0.9662 - val_loss: 0.1676 - val_accuracy: 0.9685\n",
      "Epoch 45/100\n",
      "742/742 - 2s - loss: 0.1655 - accuracy: 0.9653 - val_loss: 0.1631 - val_accuracy: 0.9688\n",
      "Epoch 46/100\n",
      "742/742 - 2s - loss: 0.1669 - accuracy: 0.9665 - val_loss: 0.1602 - val_accuracy: 0.9688\n",
      "Epoch 47/100\n",
      "742/742 - 2s - loss: 0.1571 - accuracy: 0.9674 - val_loss: 0.1808 - val_accuracy: 0.9675\n",
      "Epoch 48/100\n",
      "742/742 - 2s - loss: 0.1605 - accuracy: 0.9678 - val_loss: 0.1682 - val_accuracy: 0.9688\n",
      "Epoch 49/100\n",
      "742/742 - 2s - loss: 0.1579 - accuracy: 0.9679 - val_loss: 0.1591 - val_accuracy: 0.9705\n",
      "Epoch 50/100\n",
      "742/742 - 2s - loss: 0.1564 - accuracy: 0.9674 - val_loss: 0.1740 - val_accuracy: 0.9708\n",
      "Epoch 51/100\n",
      "742/742 - 2s - loss: 0.1637 - accuracy: 0.9673 - val_loss: 0.1543 - val_accuracy: 0.9692\n",
      "Epoch 52/100\n",
      "742/742 - 2s - loss: 0.1527 - accuracy: 0.9682 - val_loss: 0.1687 - val_accuracy: 0.9690\n",
      "Epoch 53/100\n",
      "742/742 - 2s - loss: 0.1549 - accuracy: 0.9683 - val_loss: 0.1676 - val_accuracy: 0.9679\n",
      "Epoch 54/100\n",
      "742/742 - 2s - loss: 0.1518 - accuracy: 0.9682 - val_loss: 0.1618 - val_accuracy: 0.9692\n",
      "Epoch 55/100\n",
      "742/742 - 2s - loss: 0.1460 - accuracy: 0.9698 - val_loss: 0.1822 - val_accuracy: 0.9709\n",
      "Epoch 56/100\n",
      "742/742 - 3s - loss: 0.1591 - accuracy: 0.9672 - val_loss: 0.1651 - val_accuracy: 0.9693\n",
      "Epoch 57/100\n",
      "742/742 - 2s - loss: 0.1629 - accuracy: 0.9669 - val_loss: 0.1611 - val_accuracy: 0.9697\n",
      "Epoch 58/100\n",
      "742/742 - 2s - loss: 0.1635 - accuracy: 0.9666 - val_loss: 0.1711 - val_accuracy: 0.9670\n",
      "Epoch 59/100\n",
      "742/742 - 2s - loss: 0.1640 - accuracy: 0.9662 - val_loss: 0.1623 - val_accuracy: 0.9684\n",
      "Epoch 60/100\n",
      "742/742 - 2s - loss: 0.1498 - accuracy: 0.9685 - val_loss: 0.1681 - val_accuracy: 0.9697\n",
      "Epoch 61/100\n",
      "742/742 - 2s - loss: 0.1603 - accuracy: 0.9673 - val_loss: 0.1638 - val_accuracy: 0.9688\n",
      "Epoch 62/100\n",
      "742/742 - 2s - loss: 0.1600 - accuracy: 0.9677 - val_loss: 0.1644 - val_accuracy: 0.9693\n",
      "Epoch 63/100\n",
      "742/742 - 2s - loss: 0.1551 - accuracy: 0.9689 - val_loss: 0.1770 - val_accuracy: 0.9693\n",
      "Epoch 64/100\n",
      "742/742 - 2s - loss: 0.1532 - accuracy: 0.9685 - val_loss: 0.1859 - val_accuracy: 0.9700\n",
      "Epoch 65/100\n",
      "742/742 - 2s - loss: 0.1511 - accuracy: 0.9702 - val_loss: 0.1780 - val_accuracy: 0.9702\n",
      "Epoch 66/100\n",
      "742/742 - 2s - loss: 0.1585 - accuracy: 0.9680 - val_loss: 0.1739 - val_accuracy: 0.9686\n",
      "Epoch 67/100\n",
      "742/742 - 2s - loss: 0.1524 - accuracy: 0.9688 - val_loss: 0.1578 - val_accuracy: 0.9719\n",
      "Epoch 68/100\n",
      "742/742 - 2s - loss: 0.1513 - accuracy: 0.9702 - val_loss: 0.1763 - val_accuracy: 0.9694\n",
      "Epoch 69/100\n",
      "742/742 - 2s - loss: 0.1509 - accuracy: 0.9692 - val_loss: 0.1790 - val_accuracy: 0.9692\n",
      "Epoch 70/100\n",
      "742/742 - 2s - loss: 0.1581 - accuracy: 0.9680 - val_loss: 0.1676 - val_accuracy: 0.9701\n",
      "Epoch 71/100\n",
      "742/742 - 2s - loss: 0.1470 - accuracy: 0.9700 - val_loss: 0.1730 - val_accuracy: 0.9703\n",
      "Epoch 72/100\n",
      "742/742 - 2s - loss: 0.1493 - accuracy: 0.9695 - val_loss: 0.1718 - val_accuracy: 0.9697\n",
      "Epoch 73/100\n",
      "742/742 - 2s - loss: 0.1539 - accuracy: 0.9694 - val_loss: 0.1720 - val_accuracy: 0.9698\n",
      "Epoch 74/100\n",
      "742/742 - 2s - loss: 0.1615 - accuracy: 0.9685 - val_loss: 0.1777 - val_accuracy: 0.9667\n",
      "Epoch 75/100\n",
      "742/742 - 2s - loss: 0.1504 - accuracy: 0.9702 - val_loss: 0.1609 - val_accuracy: 0.9696\n",
      "Epoch 76/100\n",
      "742/742 - 2s - loss: 0.1667 - accuracy: 0.9674 - val_loss: 0.1626 - val_accuracy: 0.9694\n",
      "Epoch 77/100\n",
      "742/742 - 2s - loss: 0.1554 - accuracy: 0.9682 - val_loss: 0.1660 - val_accuracy: 0.9689\n",
      "Epoch 78/100\n",
      "742/742 - 2s - loss: 0.1512 - accuracy: 0.9684 - val_loss: 0.1723 - val_accuracy: 0.9675\n",
      "Epoch 79/100\n",
      "742/742 - 2s - loss: 0.1523 - accuracy: 0.9690 - val_loss: 0.1603 - val_accuracy: 0.9717\n",
      "Epoch 80/100\n",
      "742/742 - 2s - loss: 0.1450 - accuracy: 0.9709 - val_loss: 0.1714 - val_accuracy: 0.9688\n",
      "Epoch 81/100\n",
      "742/742 - 2s - loss: 0.1518 - accuracy: 0.9706 - val_loss: 0.1532 - val_accuracy: 0.9708\n",
      "Epoch 82/100\n",
      "742/742 - 2s - loss: 0.1497 - accuracy: 0.9699 - val_loss: 0.1656 - val_accuracy: 0.9695\n",
      "Epoch 83/100\n",
      "742/742 - 2s - loss: 0.1541 - accuracy: 0.9693 - val_loss: 0.1657 - val_accuracy: 0.9700\n",
      "Epoch 84/100\n",
      "742/742 - 2s - loss: 0.1523 - accuracy: 0.9686 - val_loss: 0.1710 - val_accuracy: 0.9688\n",
      "Epoch 85/100\n",
      "742/742 - 2s - loss: 0.1577 - accuracy: 0.9681 - val_loss: 0.1645 - val_accuracy: 0.9685\n",
      "Epoch 86/100\n",
      "742/742 - 2s - loss: 0.1552 - accuracy: 0.9700 - val_loss: 0.1754 - val_accuracy: 0.9691\n",
      "Epoch 87/100\n",
      "742/742 - 2s - loss: 0.1473 - accuracy: 0.9696 - val_loss: 0.1684 - val_accuracy: 0.9706\n",
      "Epoch 88/100\n",
      "742/742 - 2s - loss: 0.1476 - accuracy: 0.9707 - val_loss: 0.1622 - val_accuracy: 0.9699\n",
      "Epoch 89/100\n",
      "742/742 - 2s - loss: 0.1539 - accuracy: 0.9693 - val_loss: 0.1601 - val_accuracy: 0.9696\n",
      "Epoch 90/100\n",
      "742/742 - 2s - loss: 0.1473 - accuracy: 0.9712 - val_loss: 0.1740 - val_accuracy: 0.9691\n",
      "Epoch 91/100\n",
      "742/742 - 2s - loss: 0.1573 - accuracy: 0.9687 - val_loss: 0.1572 - val_accuracy: 0.9698\n",
      "Epoch 92/100\n",
      "742/742 - 2s - loss: 0.1548 - accuracy: 0.9689 - val_loss: 0.1777 - val_accuracy: 0.9681\n",
      "Epoch 93/100\n",
      "742/742 - 2s - loss: 0.1523 - accuracy: 0.9703 - val_loss: 0.1721 - val_accuracy: 0.9698\n",
      "Epoch 94/100\n",
      "742/742 - 2s - loss: 0.1478 - accuracy: 0.9702 - val_loss: 0.1602 - val_accuracy: 0.9715\n",
      "Epoch 95/100\n",
      "742/742 - 2s - loss: 0.1513 - accuracy: 0.9709 - val_loss: 0.1580 - val_accuracy: 0.9693\n",
      "Epoch 96/100\n",
      "742/742 - 2s - loss: 0.1490 - accuracy: 0.9701 - val_loss: 0.1677 - val_accuracy: 0.9695\n",
      "Epoch 97/100\n",
      "742/742 - 2s - loss: 0.1512 - accuracy: 0.9705 - val_loss: 0.1693 - val_accuracy: 0.9686\n",
      "Epoch 98/100\n",
      "742/742 - 2s - loss: 0.1507 - accuracy: 0.9698 - val_loss: 0.1669 - val_accuracy: 0.9704\n",
      "Epoch 99/100\n",
      "742/742 - 2s - loss: 0.1522 - accuracy: 0.9690 - val_loss: 0.1703 - val_accuracy: 0.9695\n",
      "Epoch 100/100\n",
      "742/742 - 2s - loss: 0.1455 - accuracy: 0.9710 - val_loss: 0.1667 - val_accuracy: 0.9708\n",
      "Accuracy: 96.15\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0753 - accuracy: 0.9850\n",
      "Accuracy: 98.50\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1630 - accuracy: 0.9699\n",
      "Accuracy: 96.99\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='softmax'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(64, input_dim=input_size, activation='sigmoid'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.02, beta_1=0.87, beta_2=0.991, epsilon=1e-07, amsgrad=False, name=\"Adam\"),metrics=['accuracy'])\n",
    "history_init = model.fit((train_x), (train_y),validation_data=((val_x),(val_y)),batch_size=68,epochs=100, verbose = 2)\n",
    "x = mean(history_init.history['accuracy'])\n",
    "print('Accuracy: %.2f' % (x*100))   \n",
    "_, accuracy = model.evaluate(x_train,y_train)\n",
    "print('Accuracy: %.2f' % (accuracy*100))   \n",
    "_, accuracy = model.evaluate(x_test,y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d3f300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highest accuracy test is 97.20"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
